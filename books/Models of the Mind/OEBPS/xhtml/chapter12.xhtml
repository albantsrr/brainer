<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML" lang="en" xml:lang="en">
<head>
<title>Chapter 12</title>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000006607108" name="Adept.expected.resource"/>
</head>
<body>
<p class="CN" id="chapter12"><a href="contents.xhtml#re_chapter12">CHAPTER TWELVE</a></p>
<p class="CT"><a href="contents.xhtml#re_chapter12">Grand Unified Theories of the Brain</a><a id="page_341"/></p>
<p class="H1" id="b-9781472966445-ch1290-sec13">
<span class="bold">
<span>Free energy principle, Thousand Brains Theory and integrated information theory</span>
</span></p>
<p class="TXT">One of the biggest shockwaves in the history of science hit physics in the mid-nineteenth century. James Clerk Maxwell, a Scottish mathematician, published his seven-part paper ‘A dynamical theory of the electromagnetic field’ in 1865. Through this marathon of insightful analogies and equations, Maxwell demonstrated a deep and important relationship between two already important forms of physical interaction: electricity and magnetism. Specifically, by defining electromagnetic field theory, Maxwell created the mathematical infrastructure needed to see the equations of electricity and magnetism as two sides of the same coin. In the process, he concluded that a third important object – light – was a wave in this electromagnetic field. </p>
<p class="TXI">Scientists had, of course, studied electricity, magnetism and light for centuries before Maxwell. And they had learned a fair bit about them, how they interact and how they can be harnessed. But Maxwell’s unification provided something profoundly different – a whole new way to interpret the physical world. It was the first domino to fall in a series of landmark discoveries in foundational <a id="page_342"/>physics and paved the way for many of today’s technologies. Einstein’s work, for example, is built on electromagnetic field theory and he reportedly credited his success to standing ‘on the shoulders of Maxwell’. </p>
<p class="TXI">More than its direct impact on research, however, Maxwell’s theory planted the thought in the minds of future physicists that more subterranean relationships may exist among physical forces. Digging up these connections became a major aim of theoretical physics. By the twentieth century an explicit search for what are known as grand unified theories (GUTs) was on. At the top of the to-do list was finding a GUT that could further unify electromagnetism with two other forces: the weak force (which governs radioactive decay) and the strong force (which holds atomic nuclei together). A big step in this direction came in the early 1970s with the discovery that the weak force and electromagnetism become one at very high temperatures. Even so, bringing in the strong and weak forces still leaves out another big one, gravity. Physicists, therefore, remain in pursuit of a full GUT. </p>
<p class="TXI">GUTs tap into the aesthetic preferences of many physicists: simplicity, elegance, totality. They demonstrate how the whole can become greater than the sum of its parts. Before identifying a GUT, scientists are like the blind men touching an elephant in the old parable. They’re each relying on what little information they can grab from the trunk, the leg or the tail. Through this they come up with separate and incomplete stories about what each bit is doing. Once the entire elephant is seen, however, the pieces lock into place and each is understood in context of the others. The deep wisdom obtained by finally finding a GUT can’t be approximated <a id="page_343"/>by studying the parts separately. Therefore, as difficult as they can be to find, the search for GUTs is largely deemed a worthwhile endeavour by the physics community. As physicist Dimitri Nanopoulos wrote in 1979, shortly after helping to coin the phrase, ‘grand unified theories give a very nice and plausible explanation of a whole lot of different and at first sight unrelated phenomena, and they definitely have the merit and right to be taken seriously’.</p>
<p class="TXI">But should GUTs of the brain be taken seriously? The notion that a small number of simple principles or equations will be able to explain everything about the form and function of the brain is appealing for the same reasons GUTs are coveted in physics. However, most scientists who study the brain are doubtful they could exist. As psychologists Michael Anderson and Tony Chemero wrote: ‘There is every reason to think that there can be no grand unified theory of brain function because there is every reason to think that an organ as complex as the brain functions according to diverse principles.’ A GUT for the brain, as great as it would be, is considered a fantasy by many. </p>
<p class="TXI">On the other hand, so much of what has been imported from physics to neuroscience – the models, the equations, the mindset – has helped advance the field in one direction or another. GUTs, core as they are to modern physics, are hard to ignore. They can be tantalising for those who study the brain even if they seem unlikely and to some scientists they are simply too seductive to pass up. </p>
<p class="TXI">Searching for a GUT in the brain is a high risk-high reward endeavour. As such, it tends to require a big <a id="page_344"/>personality to lead it. Most candidate GUTs of the brain have a frontman of sorts – a scientist, usually the one who first developed the theory, who functions as the public face of it. To get a GUT to succeed also requires dedication: supporters of a theory will work for years, even decades, on refining it. And they’re always on the prowl for new ways of applying their theory to every facet of the brain they can find. Advocacy is important, too; even the grandest of GUTs can’t help to explain much if no one has heard of it. Therefore, many papers, articles and books have been written to communicate GUTs not just to the scientific community but to the world at large. It’s best for GUT enthusiasts to have a thick skin, however. Pushing of such theories can be met with disdain from the mass of scientists doing the more reliable work of studying the brain one piece at a time. </p>
<p class="TXI">Sociologist Murray S. Davis offered a reflection on theories in his 1971 article entitled ‘That’s interesting!’ In it, he said: ‘It has long been thought that a theorist is considered great because his theories are true, but this is false. A theorist is considered great, not because his theories are true, but because they are <span class="italic">interesting</span> … In fact, the truth of a theory has very little to do with its impact, for a theory can continue to be found interesting even though its truth is disputed – even refuted!’ Grand unified theories of the brain, whatever their truth may be, are surely interesting.</p>
<p class="center">* * *</p>
<p class="TXT">Generally jovial and soft-spoken, British neuroscientist Karl Friston doesn’t quite fit the profile for the leader of <a id="page_345"/>an ambitious and controversial scientific movement. Yet he certainly has the devoted following of one. Scientists – ranging from students to professors, including those well outside the traditional bounds of neuroscience – gather ritualistically on Mondays to receive a few moments of his insights each. They are there to seek his unique wisdom mainly on one topic. It is an all-encompassing framework on which Friston has been building an understanding of the brain, behaviour and beyond for over 15 years: the free energy principle.</p>
<p class="TXI">‘Free energy’ is a mathematical term defined by differences between probability distributions. Yet its meaning in Friston’s framework can be summarised somewhat simply: free energy is the difference between the brain’s predictions about the world and the actual information it receives. The free energy principle says that everything the brain does can be understood as an attempt to minimise free energy – that is, to make the brain’s predictions align as much as possible with reality. </p>
<p class="TXI">Inspired by this way of understanding, many researchers have gone on a search for where predictions may be made in the brain and how they may get checked against reality. A small industry of research built around the idea of ‘predictive coding’ explores how this could be happening in sensory processing in particular.<sup><a href="#fn-1" id="fnt-1">1</a>
</sup> In most predictive coding models, information gets sent as normal through the sensory processing system. For <a id="page_346"/>example, auditory information comes in from the ears, gets relayed first through regions in the brainstem and midbrain, and then goes on to be passed sequentially through several areas in the cortex. This <span class="italic">forward</span> pathway is widely accepted as crucial for how sensory information gets turned into perception, even by researchers who don’t hold much stock in the theory of predictive coding.</p>
<p class="TXI">What makes predictive coding unique is what it claims about the <span class="italic">backward</span> pathway – connections going from latter areas to earlier ones (say from the second auditory area in the cortex back to the first). In general, scientists have hypothesised many different roles for these projections. According to the predictive coding hypothesis, these connections carry predictions. For example, when listening to your favourite song, your auditory system may have very precise knowledge about the upcoming notes and lyrics. Under a predictive coding model, these predictions would be sent backwards and get combined with forward-coming information about what’s actually happening in the world. By comparing these two streams, the brain can calculate the error between its prediction and reality. In fact, in most predictive coding models, specific ‘error’ neurons are tasked with just this calculation. Their activity thus indicates just how wrong the brain was: if they are firing a lot, the error in prediction was high, if they’re quiet, it was low. In this way, the activity of these neurons is a physical instantiation of free energy. And, according to the free energy principle, the brain should aim to make these neurons fire as little as possible.</p>
<p class="TXI">Do such error neurons exist in sensory pathways? And does the brain learn to quiet them by making <a id="page_347"/>better predictions about the world? Scientists have been looking for answers to these questions for many years. A study conducted by researchers at Goethe University Frankfurt, for example, found that some neurons in the auditory system do decrease their firing when an expected sound is heard. Specifically, the researchers trained mice to press a noise-making lever. When the mice heard the expected sound after pressing the lever, their neurons responded less than if that same sound were played at random or if the lever made an unexpected sound. This suggests the mice had a prediction in mind and the neurons in their auditory system were firing more when that prediction was violated. Overall, however, the evidence for predictive coding is mixed. Not all studies that go looking for error neurons find them and, even when they do, these neurons don’t always behave exactly as the predictive coding hypothesis would predict. </p>
<p class="TXI">Making the brain a better predictive machine might seem like the most obvious way of minimising free energy, but it’s not the only one. Because free energy is the difference between the brain’s prediction and experience, it can also be minimised by controlling experience. Imagine a bird that has grown accustomed to flying around a certain forest; it can predict which trees will be good for nest building, where the best food is found and so on. One day it flies a little beyond its normal range and finds itself in a city. Experiencing tall buildings and traffic for the first time, its ability to predict almost anything about the world around it is low. This big discrepancy between prediction and experience means free energy is high. To bring its free energy back <a id="page_348"/>down, the bird could stick around and hope its sensory systems adapt to be able to predict the features of city life. Or it could simply fly back to the forest it came from. The presence of this second option – choosing actions that result in predictable sensory experiences – is what makes the free energy principle a candidate GUT of the brain. Rather than just explaining features of sensory processing, this principle can encompass decisions about behaviour as well. </p>
<p class="TXI">The free energy principle has indeed been invoked to explain perception, action and everything in between.<sup><a href="#fn-2" id="fnt-2">2</a>
</sup> This includes processes like learning, sleep and attention, as well as disorders like schizophrenia and addiction. It is also argued that the principle can account for the anatomy of neurons and brain areas, along with the details of how they communicate. In fact, Friston hasn’t even constrained free energy to the brain. He’s argued for it as a guiding principle of all of biology and evolution and even as a way of understanding the fundamentals of physics. </p>
<p class="TXI">This tendency to try to wrap complex topics into simple packages has been with Friston throughout his life. In a 2018 <span class="italic">Wired</span> profile, he recalls a thought he had as a teenager: ‘There must be a way of understanding everything by starting from nothing … If I’m only allowed to start off with one point in the entire universe, can I derive everything else I need from that?’ In <a id="page_349"/>Friston’s world, the free energy principle is now the nearly nothing that can explain almost everything.</p>
<p class="TXI">Outside Friston’s world, however, the capabilities of the free energy principle aren’t always as obvious. Given its grand promises, countless scientists have attempted to understand the ins and outs of Friston’s theory. Few (even those who count themselves fans of the principle) consider their attempts wholly successful. It’s not necessarily that the equations are too complicated – many of the scientists trying have dedicated their lives to understanding the mathematics of the mind. Rather, how to extrapolate and apply the free energy principle to all the nooks and crannies of brain function requires a type of intuition that seems to run strongest in Friston himself. Without a clear and objective means of interpreting free energy in any particular case, Friston is left to play the role of free energy whisperer, laying out his take on its implications in countless papers, talks, and Monday meetings. </p>
<p class="TXI">The confusion around the free energy principle likely results from a feature of it that Friston readily acknowledges: it’s not falsifiable. Most hypotheses about how the brain functions are falsifiable – that is, they make claims that can be proven wrong through experiments. The free energy principle, however, is more a way of looking at the brain than a strong or specific claim about how it works. As Friston said: ‘The free energy principle is what it is—a principle … there’s not much you can do with it, unless you ask whether measurable systems conform to the principle.’ In other words, rather than trying to make clean predictions about the brain based on the free energy principle, <a id="page_350"/>scientists should instead ask if the principle helps them see things in a new light. Trying to figure out how a bit of the brain works? Ask if it somehow minimises free energy. If that leads to progress, great; if not, that’s fine, too. In this way, the free energy principle is meant to at best offer a scaffolding on which to hang facts about the brain. Insofar as it can connect a great many facts, it is grand and somewhat unifying; however – without falsifiability – its status as a theory is more questionable. </p>
<p class="center">* * *</p>
<p class="TXT">Numenta is a small tech company based in Redwood City, California. It was founded by Jeff Hawkins, an entrepreneur who previously founded two companies that produced predecessors to the modern smartphone. Numenta, on the other hand, makes software. The company designs data-processing algorithms aimed to help stockbrokers, energy distributors, IT companies and the like identify and track patterns in streams of incoming data. Numenta’s main goal, however, is to reverse-engineer the brain. </p>
<p class="TXI">Even as he weaved his way through an illustrious career in tech, Hawkins always harboured an interest in the brain. Despite never earning a degree in the field himself, he started the Redwood Neuroscience Institute in 2002. The institute would go on to become part of the University of California, Berkeley, and Hawkins would go on to Numenta in 2005. The work of Numenta is based mainly on ideas presented in a 2004 book Hawkins co-authored with Sandra Blakeslee, <span class="italic">On Intelligence</span>. The book summarises Hawkins’ theory about <a id="page_351"/>how the neocortex – the thin layer of brain tissue covering the surface of mammalian brains – works to produce sensation, cognition, learning, movement and more. It’s a set of ideas that now goes under the name ‘The Thousand Brains Theory of Intelligence’. </p>
<p class="TXI">At the centre of the Thousand Brains Theory is a piece of neuro-architecture known as the cortical column. Cortical columns are small patches of cells, less than the tip of a pencil in diameter and about four times that in length. They’re so-named because they form cylinders running from the top of the neocortex through to the bottom, like so many parallel strands of spaghetti. Looking at a column length-wise, it resembles sheets of sediment: the neurons are segregated into six visibly identifiable layers. Neurons in different layers interact with each other by sending connections up or down. Typically, all the neurons in a column perform a similar function; they may all, for example, respond in a similar way to a sensory input. Yet the different layers do seem to serve some different purposes: some layers, for example, get input from other brain areas and other layers send output off. </p>
<p class="TXI">Vernon Mountcastle, the sensory neuroscientist who first identified these columns in the mid-twentieth century, believed they represented a fundamental anatomical unit of the brain. Though it went against the dogma of the time, Mountcastle saw potential in the idea of a single repeating unit that tiles the whole of the neocortex – a single unit that could process the full variety of information the cortex receives. Hawkins agrees. In his book, he describes Mountcastle’s work as ‘the Rosetta stone of neuroscience’ because it is ‘a single <a id="page_352"/>idea that united all the diverse and wondrous capabilities of the human mind’. </p>
<p class="TXI">To understand what Hawkins thinks these mini-processing units do we have to consider both time and space. ‘If you accept the fact intelligent machines are going to work on the principles of the neocortex,’ Hawkins said in a 2014 interview, ‘[time] is the entire thing.’ Inputs to the brain are constantly changing; this makes a static model of brain function woefully incomplete. What’s more, the outputs of the brain – the behaviours produced by the body – are extended through both space and time. According to Hawkins, actively moving the body through space and getting dynamic streams of sensory data in return helps the brain build a deep understanding of the world. </p>
<p class="TXI">Neuroscientists know a bit about how animals move through the world. It has a lot to do with a type of neuron called a ‘grid cell’ (see Figure 26).<sup><a href="#fn-3" id="fnt-3">3</a>
</sup> Grid cells are neurons that are active when an animal is in certain special locations. Imagine a mouse running around an open field. One of its grid cells will be active when the mouse is right in the middle of the field. That same cell will <span class="italic">also</span> be active when the mouse has moved a few body lengths north of the centre and then again a few lengths north of that. The same pattern of activity would also be seen if the mouse went 60 degrees west of north instead. In fact, if you made a map of all the places this cell is active it would form a polka-dot pattern across the <a id="page_353"/>whole field. These polka dots would all be evenly spaced at the vertices of a triangular grid (hence the name). Different grid cells differ in the size and orientation of this grid, but they all share this common feature.</p>
<p class="image-fig" id="fig26.jpg">
<img alt="" src="../images/fig26.jpg"/></p>
<p class="FC"> 
<span class="bold">
<span class="italic">Figure 26</span>
</span></p>
<p class="TXI">Impressed by their ability to represent space, Hawkins made grid cells an integral part of his theory of how the neocortex learns about the world. There is a problem, however: grid cells aren’t found in the neocortex. Instead, they reside in an evolutionarily older part of the brain known as the entorhinal cortex. Despite little evidence for grid cells outside of this region, Hawkins hypothesises that they are actually hiding away in the sixth layer of every column in the neocortex. </p>
<p class="TXI">What exactly are they doing there? To explain this, Hawkins likes to use the example of running your finger around a coffee cup (Hawkins actually attributes the origins of his theory to a eureka moment he had while contemplating a coffee cup and will even bring the cup to talks for demonstration). Columns in the sensory processing part of the neocortex will get inputs from the fingertip. According to Hawkins’ theory, the grid cells at the bottom of these columns will also be tracking the location of the fingertip. Combining information about <a id="page_354"/>where the finger is and what the cup feels like there, the column can learn the shape of the object as it navigates around it. The next time the same object is encountered the column can use this stored knowledge to recognise it. </p>
<p class="TXI">As these cortical columns exist across the neocortex, this process could be happening in parallel everywhere. The columns that represent other parts of the hand, for example, would be building their own models of the coffee cup as they come into contact with it. And areas in the visual system would combine visual information with the location of the eyes to build their own understanding of the cup, too. In total, a cohesive understanding of the world is built through these distributed contributions, like thousands of brains working in unison.</p>
<p class="TXI">Hawkins’ theory is ever-evolving and many of the details are still to be worked out, but his hopes for it are high. The way he sees it, just as columns could learn the shapes of literal objects, so too could they learn the shapes of abstract ones. Navigating the space of thought or language can be accomplished with the same mechanisms for navigating the real, physical world. If this is true, it explains how a repeating pattern in the neocortex can be used to do so many different things, from vision to audition, movement to mathematics. </p>
<p class="TXI">Exactly how identical these columns are, however, is a subject of debate. At a glance the neocortex may appear like a uniform tessellation, but upon closer inspection differences do emerge. Some studies have found that the size of columns, the number and type of neurons they contain, and how they interact with each other varies across regions of the neocortex. If these columns are not <a id="page_355"/>actually anatomically identical, they may differ in function, too. This means that each brain region could be more specialised for the kind of tasks it has to perform than the Thousand Brains Theory assumes. If that’s the case, the hope for a universal algorithm of intelligence may be dashed. </p>
<p class="TXI">As seen throughout this book, mathematical models of the brain are usually built by first identifying – out of the mounds of available data – a selection of facts that seem relevant. Those facts are then simplified and pieced together in a way that demonstrates how, in theory, a bit of the brain could work. Additionally, in figuring out how exactly to cobble this toy version of biology together, some new and surprising predictions may be made. When compared to this schema, the Thousand Brains Theory is a model like any other in neuroscience. Indeed, many of the component concepts – columns, grid cells, object recognition – have already been studied extensively by means of both experimental and computational work. In this way, the theory is not unique; it’s a guess that may be right, may be wrong or may – like many theories – be a little of both. </p>
<p class="TXI">Perhaps what sets the work of Hawkins and Numenta apart then is simply the unrelenting optimism that this one <span class="italic">is</span> different – that for the first time a key that will unlock all the doors of the cortex is truly within reach. When asked in a 2019 interview about how far off a full understanding of the neocortex is, Hawkins said: ‘I feel I’ve already passed a step function. So, if I can do my job correctly over the next five years – meaning I can proselytise these ideas, I can convince other people they’re right, we can show that other machine learning <a id="page_356"/>people should pay attention to these ideas – then we’re definitely in an under 20-year timeframe.’ That’s a confidence not commonly seen in scientists – and because Hawkins has the private funding to back it, it’s a confidence that is not constrained by normal scientific pressures. </p>
<p class="TXI">Hawkins is known to be self-assured in his claims about the brain. However, his past ability to deliver on promises for breakthrough brain-based algorithms has been questionable. Geoffrey Hinton, a leader in artificial intelligence research, has described Hawkins’ contributions to the field as ‘disappointing’. And in 2015, psychology professor Gary Marcus compared Numenta’s work to other AI techniques by saying: ‘I have not seen a knock-down argument that they yield better performance in any major challenge area.’ What chance does the Thousand Brains Theory have of ever providing the field with a set of truly universal mechanisms of intelligence? Only time – a concept so central to Hawkins’ thinking – will tell. </p>
<p class="center">* * *</p>
<p class="TXT">By some accounts, no theory of the brain could be complete without explaining its biggest and most enduring mystery: consciousness. The C-word can be a tough subject for scientists, laden as it is with centuries of philosophical baggage. Yet, in the eyes of certain researchers, a precise scientific definition that could be used to not just identify but also <span class="italic">quantify</span> consciousness anywhere it may exist is the holy grail of their work. It is also the promise of ‘integrated information theory’.</p> <a id="page_357"/>
<p class="TXI">Integrated information theory (or IIT) is an attempt to define consciousness with an equation. It was originally put forth by Italian neuroscientist Giulio Tononi in 2004 and has been iterated on by him and others ever since. IIT is designed to measure consciousness in anything: in computers, rocks and aliens as easily as in brains. By making a universal claim of what consciousness is, it differs from the more biology-centred theories devised by some neuroscientists.</p>
<p class="TXI">IIT is able to free itself from the specific physical features of the brain because its inspiration comes from another source entirely: introspection. By reflecting on the first-person conscious experience, Tononi came up with five important traits fundamental to consciousness; these are the ‘axioms’ on which IIT is built. The first axiom is the basic fact that consciousness exists. Others include the observation that a conscious experience is composed of multiple distinct sensations, the experience is specific, it appears to us as an integrated whole and it is uniquely what it is – no more or less. </p>
<p class="TXI">Tononi considered what kinds of information-processing systems could give rise to these axioms of experience. Through this, he was able to map the axioms to mathematical terms. The end result is a unified measure of what is called ‘integrated information’, a value Tononi symbolises with the Greek letter <span class="italic">phi</span>. In total, phi indicates just how intermixed the information in a system is. The right kind of intermixing is supposed to give rise to the richness and wholeness of experience. According to IIT, the higher the phi that a system has, the more conscious it is.</p> <a id="page_358"/>
<p class="TXI">As it turns out, calculating the phi for a system with any reasonable amount of complexity is nearly impossible. For the human brain, it would first require conducting a near endless amount of experiments in order to probe how the different sub-structures of the brain interact. Even if that could be done, a long and gruelling series of computations would then begin. To overcome this hurdle, multiple approximations to phi have been devised. Through this, it is possible to make educated guesses about the phi in a system. This has been used to explain why certain brain states lead to more conscious experience than others. For example, during sleep, the ability of neurons to communicate effectively is interrupted. This makes the brain less able to integrate information, resulting in lower phi. According to Tononi’s theory, similar reasoning can explain the unconsciousness that comes with seizures as well. </p>
<p class="TXI">The theory also makes some, perhaps surprising, predictions. For example, the phi of an average thermostat is small, but still not zero. This implies that the device regulating your room temperature has some amount of conscious experience. What’s more, some very simple devices – if built just right – can actually have a value of phi much higher than the estimated phi of the human brain. These counterintuitive conclusions make some scientists and philosophers sceptical of IIT. </p>
<p class="TXI">Another critique of the theory is targeted at its axiomatic basis. According to this argument, the axioms Tononi chose aren’t the only ones that a theory of consciousness could be built on. And his way of mapping these axioms to mathematics isn’t obviously the only, or best, way either. The problem is: if the foundations of IIT <a id="page_359"/>are arbitrary, then how can we trust the conclusions that spring from them, especially when they surprise us? </p>
<p class="TXI">An informal survey of consciousness scientists conducted in 2018 revealed that IIT was not the favoured theory among experts (it came in fourth after two other theories and the catch-all category of ‘other’). But the same survey found that IIT fared better among non-experts: in fact, it was rated first among the subset of non-experts who felt they had enough knowledge to respond. Some of the survey authors suspect this may be a result of IIT’s PR. From the outside, the theory looks well founded if only because it has the authority of hard math behind it. And more than most scientific theories of consciousness, IIT has been featured in the popular press. This includes writings by Christof Koch, a prominent neuroscientist who has become a collaborator of Tononi’s and a public advocate of IIT. In his book, <span class="italic">Consciousness: Confessions of a Romantic Reductionist</span>, Koch describes his personal journey through the scientific study of consciousness, including work he did with Nobel Prize winner Francis Crick, and his views on IIT.<sup><a href="#fn-4" id="fnt-4">4</a>
</sup> Such popular accounts may be effective in getting the theory out to a broader audience, but don’t necessarily convince scientists in the know. </p>
<p class="TXI">Even scientists who lack faith in the power of IIT still tend to applaud the attempt. Consciousness is a notoriously <a id="page_360"/>difficult concept to tame, which makes IIT’s effort to submit it to orderly scientific inquiry still a step in the right direction. As vocal critic of IIT physicist Scott Aaronson wrote on his blog: ‘The fact that integrated information theory is wrong – demonstrably wrong, for reasons that go to its core – puts it in something like the top 2 per cent of all mathematical theories of consciousness ever proposed. Almost all competing theories of consciousness, it seems to me, have been so vague, fluffy and malleable that they can only <span class="bold">aspire</span> to wrongness.’ </p>
<p class="center">* * *</p>
<p class="TXT">GUTs can be a slippery thing. To be grand and unifying, they must make simple claims about an incredibly complex object. Almost any statement about ‘the brain’ is guaranteed to have exceptions lurking somewhere. Therefore, making a GUT too grand means it won’t actually be able to explain much specific data. But, tie it too much to specific data and it’s no longer grand. Whether untestable, untested, or tested and failed, GUTs of the brain, in trying to explain too much, risk explaining nothing at all.</p>
<p class="TXI">While this presents an uphill battle for GUT-seeking neuroscientists, it’s less of a challenge in physics. The reason for this difference may be simple: evolution. Nervous systems evolved over eons to suit the needs of a series of specific animals in specific locations facing specific challenges. When studying such a product of natural selection, scientists aren’t entitled to simplicity. Biology took whatever route it needed to create functioning organisms, without regard to how understandable any part of them would be. It should be no surprise, then, to find <a id="page_361"/>that the brain is a mere hodgepodge of different components and mechanisms. That’s all it needs to be to function. In total, there is no guarantee – and maybe not even any compelling reasons to expect – that the brain can be described by simple laws.</p>
<p class="TXI">Some scientists choose to embrace this mess. Instead of reducing the brain to its barest elements, they build a form of ‘grand unified model’ that sticks all of the parts together. While traditional GUTs have the simplicity of a steak cooked with just a sprinkle of salt, these models are more like a big pot of soup. And while they’re not as sleek and elegant as GUTs, they may be better equipped to get the job done. </p>
<p class="TXI">The hyper-detailed simulation built by the Blue Brain Project, as discussed in <a href="chapter2.xhtml#chapter2">Chapter 2</a>, is one example of this more inclusive approach. These researchers extracted countless details about neurons and synapses through a series of painstaking experiments. They then pieced all this data back together into an elaborate computational model of just a small speck of the brain. Such an approach assumes that each detail is precious and that the brain won’t be understood by stripping them away. It’s a wholehearted embrace of the nuance of biology, with the hope that by throwing everything together, a fuller understanding of what makes the brain work will emerge. The trouble here, however, is scale. A bottom-up approach to rebuilding the brain can only proceed one neuron at a time, which means a complete model is a long way off. </p>
<p class="TXI">The Semantic Pointer Architecture Unified Network, better known as SPAUN, comes at things from a very different direction. Rather than capturing <a id="page_362"/>all the minutiae of the neurobiology, SPAUN – developed by a team working under Chris Eliasmith at University of Waterloo in Ontario, Canada – is about making a model of the brain that works. That means getting the same sensory inputs and having the same motor outputs. Specifically, SPAUN has access to images as input and controls a simulated arm to write its outputs. In between this input and output is a complex web of 2.5 million simple model neurons, arranged to broadly mimic the structure of the whole brain. Through these neural connections SPAUN can perform seven different cognitive and motor tasks, such as drawing digits, recalling lists of objects and completing simple patterns. In this way, SPAUN eschews elegance for function. Of course, the human brain contains tens of thousands of times as many neurons and can do a lot more than seven tasks. Whether the principles of utility and scale that got SPAUN to where it is can take it all the way up to a full model of the brain – or whether more of the nuances of neurons need to be added – is unknown.</p>
<p class="TXI">True GUTs aim to condense. They melt diverse information down into a compact and digestible form. This makes GUTs seem satisfying because they give the sense that the workings of the brain can be fully grasped in one hand. Models like SPAUN and the Blue Brain Project simulation, however, are expansive. They bring in many sources of data and use them to build an elaborate structure. In this way, they sacrifice interpretability for accuracy. They aim to explain everything by incorporating everything there is to explain.</p> <a id="page_363"/>
<p class="TXI">Though as with all models, even these more expansive ones are still not perfect replicas. Makers of these models still need to choose what to include and what not to include, what they aim to explain and what they can ignore. When aiming for something akin to a GUT, the hope is always to find the simplest set of principles that can explain the largest set of facts. With an object as dense and messy as the brain, that simple set may still be pretty complicated. To know in advance what level of detail and what magnitude of scale will be needed to capture the relevant features of brain function is impossible. It is only through the building and testing of models that progress on that question can be made. </p>
<p class="TXI">On the whole, neuroscience has enjoyed a very fruitful relationship with the ‘harder’, more quantitative sciences. It has received many gifts from the likes of physics, mathematics and engineering. These analogies, methods and tools have shifted thinking about everything from neurons to behaviour. And the study of the brain has given back in return, providing inspiration for artificial intelligence and a testing ground for mathematical techniques. </p>
<p class="TXI">But neuroscience is not physics. It must avoid playing the role of the kid sibling, trying to follow exactly in the footsteps of this older discipline. The principles that guide physics and the strategies that have led it to success won’t always work when applied to biology. Inspiration, therefore, must be taken with care. When building models of the mind, the aesthetics of the mathematics is not the only guiding light. Rather, this influence needs <a id="page_364"/>always to be weighed against the unique realities of the brain. When balanced just right, the intricacies of the biology can be reduced to mathematics in a way that produces true insights and isn’t overly influenced by other fields. In this way, the study of the brain is forging its own path for how to use mathematics to understand the natural world.</p> 
<p class="H1">Notes</p>
<p class="FN1"><a href="chapter12.xhtml#fnt-1" id="fn-1">1</a> ﻿The predictive coding scheme was actually developed in the absence of any influence from Friston or free energy; it debuted in a paper by Rajesh Rao and Dana Ballard in 1999. However, free energy fans have since eagerly explored it. ﻿</p>
<p class="FN1"><a href="chapter12.xhtml#fnt-2" id="fn-2">2</a> ﻿When fully splayed out, the tendrils of the free energy principle reach into many of the topics covered in this book. It builds off the notion of a Bayesian brain (﻿﻿Chapter 10﻿﻿), interacts with ideas from information theory (﻿﻿Chapter 7﻿﻿), uses equations from statistical mechanics (Chapters 4 and 5) and explains elements of visual processing (﻿﻿Chapter 6﻿﻿).﻿</p>
<p class="FN1"><a href="chapter12.xhtml#fnt-3" id="fn-3">3</a> ﻿Edvard Moser, May-Britt Moser and John O﻿’﻿Keefe were awarded the Nobel Prize in 2014 for their discovery of these cells, along with the closely related, but more obviously named, ﻿‘﻿place cells﻿’﻿. ﻿</p>
<p class="FN1"><a href="chapter12.xhtml#fnt-4" id="fn-4">4</a> ﻿Tononi himself has also written a book aiming to explain his theory to a broader audience. In ﻿<span class="italic">Phi: A Voyage from the Brain to the Soul</span>﻿, Tononi tells a fictional tale of seventeenth-century scientist Galileo Galilei exploring notions of consciousness through interactions with characters inspired by Charles Darwin, Alan Turing and Crick.﻿</p>
</body>
</html>