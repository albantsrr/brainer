<html xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML" lang="en" xml:lang="en">
<head>
<title>Chapter 3</title>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000006607108" name="Adept.expected.resource"/>
</head>
<body>
<p class="CN" id="chapter3"><a href="contents.xhtml#re_chapter3">CHAPTER THREE</a></p>
<p class="CT"><a href="contents.xhtml#re_chapter3">Learning to Compute</a><a id="page_49"/></p>
<p class="H1" id="b-9781472966445-ch222-sec3">
<span class="bold">
<span>McCulloch-Pitts, the Perceptron and 
artificial neural networks</span>
</span></p>
<p class="TXT">Cambridge University mathematician Bertrand Russell spent 10 years at the beginning of the twentieth century toiling towards a monumental goal: to identify the philosophical roots from which all of mathematics stems. Undertaken in collaboration with his former teacher Alfred Whitehead, this ambitious project produced a book, the <span class="italic">Principia Mathematica</span>, which was delivered to the publishers overdue and over budget. The authors themselves had to chip in towards the publishing costs just to get it done and they didn’t see any royalties for 40 years. </p>
<p class="TXI">But the financial hurdle was perhaps the smallest one to overcome in getting this opus finished. Russell had to fight against his own agitation with the scholarly material. According to his autobiography, he spent days staring at a blank sheet of paper and evenings contemplating jumping in front of a train. Work on the book also coincided with the dissolution of Russell’s marriage and a strain on his relationship with Whitehead – who, according to Russell, was fighting his own mental and marital battles at the time. The book was even physically demanding: Russell spent 12 hours a day at a desk writing out the intricate symbolism needed <a id="page_50"/>to convey his complex mathematical ideas and when the time came to bring the manuscript to the publisher it was too large for him to carry. Despite it all, Russell and Whitehead eventually completed and published the text they hoped would tame the seemingly wild state of mathematics. </p>
<p class="TXI">The conceit of the <span class="italic">Principia</span> was that all of mathematics could be reduced to logic. In other words, Russell and Whitehead believed that a handful of basic statements, known as ‘expressions’, could be combined in just the right way to generate all the formalisms, claims and findings of mathematicians. These expressions didn’t stem from any observations of the real world. Rather, they were meant to be universal. For example, the expression: if X is true, then the statement ‘X is true or Y is true’ is also true. Such expressions are made up of propositions: fundamental units of logic that can be either true or false, written as letters like X or Y. These propositions are strung together with ‘Boolean’ operators<sup><a href="#fn-1" id="fnt-1">1</a>
</sup> such as ‘and’, ‘or’ and ‘not’. </p>
<p class="TXI">In the first volume of the <span class="italic">Principia</span>, Russell and Whitehead provided fewer than two dozen of these abstract expressions. From these humble seeds, they built mathematics. They were even able to triumphantly conclude – after scores of symbol-filled pages – that 1+1=2. </p>
<p class="TXI">Russell and Whitehead’s demonstration that the full grandeur of mathematics could be captured with the simple <a id="page_51"/>rules of logic<sup><a href="#fn-2" id="fnt-2">2</a>
</sup> had immense philosophical implications as it provided proof of the power of logic. What’s more, it meant that a subsequent finding, made by a different pair of men some 30 years later, would have immense implications of its own. This finding said that neurons, simply via the nature of their anatomy and physiology, were implementing the rules of logic. It revolutionised the study of the brain and of intelligence itself. </p>
<p class="center">* * *</p>
<p class="TXT">When Detroit native Walter Pitts was just 12 years old, he was invited by Russell to join him as a graduate student at Cambridge University. The young boy had, the story goes, encountered a copy of the <span class="italic">Principia</span> after running into a library to avoid bullies. As he read, Pitts found what he believed to be errors in the work. So, he sent his notes on the subject off to Russell, who, presumably not knowing the boy’s age, then offered him the position. Pitts didn’t accept it. But a few years later, when Russell was visiting the University of Chicago, Pitts went to sit in on his lectures. Having fled an abusive family home to come to Chicago, Pitts decided not to return. He remained in the city, homeless. </p>
<p class="TXI">Luckily, the University of Chicago had another world-famous logician for Pitts to criticise – Rudolf Carnap. Again, Pitts wrote up notes – this time identifying issues in Carnap’s recent book <span class="italic">The Logical Syntax of Language</span> – and delivered them to Carnap’s office at the University of Chicago. Pitts didn’t stick around long enough to hear his <a id="page_52"/>reaction, but Carnap, impressed, eventually chased down Pitts, whom he referred to as ‘that newsboy who understood logic’. On this occasion, the philosopher he critiqued actually did get Pitts to work with him. Though he never officially enrolled, Pitts functioned effectively as a graduate student for Carnap and fraternised with a group of scholars who were interested in the mathematics of biology.</p>
<p class="TXI">Warren McCulloch’s interest in philosophy took a more traditional form. Born in New Jersey, he studied the subject (along with psychology) at Yale and read many of the greats. He was most enamoured with Immanuel Kant and Gottfried Leibniz (whose ideas were very influential for Russell), and he read the <span class="italic">Principia</span> at the age of 25. But, despite the beard upon his long face, McCulloch was not a philosopher – he was a physiologist. He attended medical school in Manhattan and then went on to observe the panoply of ways in which the brain can break as a neurology intern at Bellevue Hospital and at the Rockland State Hospital psychiatric facility. In 1941, he joined the University of Illinois at Chicago as the director of the laboratory for basic research in the department of psychiatry. </p>
<p class="TXI">As with all great origin stories, there are conflicting accounts of how McCulloch and Pitts met. One claims that it happened when McCulloch spoke in front of a research group Pitts was a part of. Another story is that Carnap introduced them. Finally, a contemporary of the two men, Jerome Lettvin, claimed he introduced them and that all three bonded over a mutual love of Leibniz. In any case, by 1942, the 43-year-old McCulloch and his wife had taken the 18-year-old Pitts into their home, <a id="page_53"/>and the two men were spending evenings drinking whisky and discussing logic. </p>
<p class="TXI">The wall between ‘mind’ and ‘body’ was strong among scientists in the early twentieth century. The mind was considered internal and intangible; the body, including the brain, was physical. Researchers on either side of this wall toiled diligently, but separately, at their own problems. Biologists, as we saw in the last chapter, were working hard to uncover the physical machinery of neurons: using pipettes and electrodes and chemicals to sort out what causes a spike and how. Psychiatrists, on the other hand, were attempting to uncover the machinery of the mind through lengthy sessions of Freudian psychoanalysis. Few on either side would attempt a glance over the wall at the other. They spoke separate languages and worked towards different goals. For most practitioners, the question of how neural building blocks could create the structure of the mind was not just unanswered, it was unasked. </p>
<p class="TXI">But McCulloch, from as early on as his time at medical school, had immersed himself in a crowd of scientists who did care about this question and allowed him the space to think about it. Eventually, through his physiological observations, he came up with a hunch. He saw in the emerging concepts of neuroscience a possible mapping to the notions of logic and computation he so adored in philosophy. To think of the brain as a computing device following the rules of logic – rather than just a bag of proteins and chemicals – would open the door to understanding thought in terms of neural activity.</p> <a id="page_54"/>
<p class="TXI">Analytical skill, however, was not where McCulloch excelled. Some who knew him say he was too much of a romantic to be held down by such details. So, despite years of toying with these ideas in his mind and in conversation (even as a Bellevue intern he was accused of ‘trying to write an equation for the working of the brain’), McCulloch struggled with several technical issues of how to enact them. Pitts, however, was comparably unfazed by the analytical. As soon as he spoke with him about it, Pitts saw what approaches were needed to formally realise McCulloch’s intuitions. Not long after they met, one of the most influential papers on computation was written.</p>
<p class="TXI">‘A logical calculus of the ideas immanent in nervous activity’ was published in 1943. The paper is 17 pages long with many equations, only three references (one of which is to the <span class="italic">Principia</span>) and a single figure consisting of little neural circuits drawn by McCulloch’s daughter.<sup><a href="#fn-3" id="fnt-3">3</a>
</sup> </p>
<p class="TXI">The paper begins by reviewing the biology of neurons that was known at the time: neurons have cell bodies and axons; two neurons connect when the axon of the first meets the body of the second; through this connection one neuron provides input to the other; a certain amount of input is needed for a neuron to fire; a cell either fires a spike or it doesn’t – no half spikes or in-between spikes; and the input from some neurons – inhibitory neurons – has the power to prevent a cell from spiking.</p><a id="page_55"/>
<p class="TXI">McCulloch and Pitts go on to explain how these biological details are congruent with Boolean logic. The core of their claim is that the activity state of each neuron – either firing or not – is like the truth value of a proposition – either true or false. In their own words, they ‘conceive of the response of any neuron as factually equivalent to a proposition which proposed its adequate stimulus’. </p>
<p class="TXI">By ‘its adequate stimulus’ they are referring to something about the world. Imagine a neuron in the visual cortex whose activity represents the statement ‘the current visual stimulus looks like a duck’. If that neuron is firing, that statement is true; if the neuron is not firing, it is false. Now imagine another neuron, in the auditory cortex, that represents the statement ‘the current auditory stimulus is quacking like a duck’. Again, if this neuron is firing, that statement is true, otherwise it is false. </p>
<p class="TXI">Now we can use the connections between neurons to enact Boolean operations. For example, by giving a third neuron inputs from both of these neurons, we could implement the rule ‘if it looks like a duck <span class="italic">and</span> it quacks like a duck, it’s a duck’. All we have to do is build the third neuron such that it will only fire if both of its input neurons are firing. That way, both ‘looks like a duck’ and ‘quacks like a duck’ have to be true in order for the conclusion represented by the third neuron (‘it’s a duck’) to be true. </p>
<p class="TXI">This describes the simple circuit needed to implement the Boolean operation ‘and’. McCulloch and Pitts in their paper show how to implement many others. To implement ‘or’ is very similar, however the strength of the connections from each neuron must be so strong <a id="page_56"/>that one input alone is enough to make the output neuron fire. In this case, the ‘is a duck’ neuron would fire if the ‘looks like a duck’ neuron <span class="italic">or</span> the ‘quacks like a duck’ neuron (or both) were firing. The authors even show how to string together multiple Boolean operations. For example, to implement a statement like ‘X and not Y’, the neuron representing X connects to an output neuron with a strength enough to make it fire. But the neuron representing Y <span class="italic">inhibits</span> the output neuron, meaning it prevents it from firing. This way, the output neuron will only fire if the X-representing neuron <span class="italic">is</span> firing and the Y-representing neuron is <span class="italic">not</span> (see Figure 4). </p>
<p class="TXI">These circuits, which are meant to represent what networks of real neurons can do, became known as <span class="italic">artificial</span> neural networks. </p>
<p class="image-fig" id="fig4.jpg">
<img alt="" src="../images/fig4.jpg"/></p>
<p class="FC"> 
<span class="bold">
<span class="italic">Figure 4</span>
</span></p>
<p class="TXI">The ability to spot logic at play in the interactions of neurons came from McCulloch’s discerning eye. As a physiologist, he knew that neurons were more complex than his simple drawings and equations suggested. They had membranes, ion channels and forking paths of <a id="page_57"/>dendrites. But the theory didn’t need their full complexity. So, like an impressionist painter using only the necessary strokes, he intentionally highlighted only the elements of neural activity required for the story he wanted to tell. In doing so, he demonstrated the artistry inherent to model-building; it is a subjective and creative process to decide which facts belong in the foreground. </p>
<p class="TXI">The radical story that McCulloch and Pitts told with their model – that neurons were performing a logical calculus – was the first attempt to use the principles of computation to turn the mind–body problem into a mind–body connection. Networks of neurons were now imbued with all the power of a formal logical system. Like a chain of falling dominoes, once certain truth values entered into a neural population (say, via sensory organs), a cascade of interactions could deduce the truth value of new and different statements. This meant a population of neurons could carry out endless computations: interpreting sensory inputs, developing conclusions, forming plans, reasoning through arguments, performing calculations and so on. </p>
<p class="TXI">With this step in their research, McCulloch and Pitts advanced the study of human thought and, at the same time, kicked it off its throne. The ‘mind’ lost its status as mysterious and ethereal once it was brought down to solid ground – that is, once its grand abilities were reduced to the firing of neurons. To adapt a quote from Lettvin, the brain could now be thought of as ‘a machine, meaty and miraculous, but still a machine’. More boldly still, McCulloch’s student Michael Arbib later remarked that the work ‘killed dualism’.</p><a id="page_58"/>
<p class="TXI">Russell was known to lament that, despite the 20 years put into it and the impact it had on logicians and philosophers, the <span class="italic">Principia</span> had little effect on practising mathematicians. Its new take on the foundations of mathematics simply didn’t seem to mean much to those doing mathematics; it didn’t change their day-to-day work. The same could be said of McCulloch and Pitts’ discovery for neuroscientists of the time. Biologists, physiologists, anatomists – the scientists doing the labour of physically mining neurons for the details of their workings – didn’t take much from the theory. This was in part because it wasn’t obvious what experiments should follow from it. But it may also have stemmed from the very technical notation in the paper and its less-than-inviting writing style. In a review on nerve conduction written three years later, the author refers to the McCulloch-Pitts paper as ‘not for the lay reader’ and remarks that if this style of work is to be useful, it’s necessary for ‘physiologists to familiarise themselves with mathematical technology, or for mathematicians to elaborate at least their conclusions in a less formidable language’. The wall between mind and body may have come down, but the one between biologist and mathematician stood strong. </p>
<p class="TXI">There was a separate group of people – a group with the requisite technical know-how – who did take an interest in the logical calculus of neurons. In the post-war era, a series of meetings hosted by the philanthropic Macy Foundation brought together biologists and technologists, many of whom wished to use biological findings to build brain-like machines. McCulloch was an organiser of these meetings, and fellow attendees <a id="page_59"/>included the ‘father of cybernetics’ Norbert Wiener and John von Neumann, the inventor of the modern computer architecture, who was directly inspired in its design by the McCulloch-Pitts neurons. As Lettvin described it 40 years later: ‘The whole field of neurology and neurobiology ignored the structure, the message and the form of McCulloch and Pitts’ theory. Instead, those who were inspired by it were those who were destined to become the aficionados of a new venture, now called Artificial Intelligence.’</p>
<p class="center">* * *</p>
<p class="EXTF">The <span class="italic">Navy last week demonstrated the embryo of an electronic computer named the Perceptron which, when completed in about a year, is expected to be the first non-living mechanism able to 
‘perceive, recognise, and identify its surroundings without human training or control.’ [...]</span> </p>
<p class="EXT-L">
<span class="italic">“‘Dr. Frank Rosenblatt, research psychologist at the Cornell Aeronautical Laboratory, Inc., Buffalo, NY, designer of the ­Perceptron, conducted the demonstration. The machine, he said, would be the first electronic device to think as the human brain. Like humans, Perceptron will make mistakes at first, ‘but it will grow wiser as it gains experience’, he said.</span></p>
<p class="TXT">This summary, from an article entitled ‘Electronic “brain” teaches itself’, appeared in the 13 July 1958 edition of the <span class="italic">New York Times</span>, opposite a letter to the editor about the ongoing debate on whether smoking causes cancer. Frank Rosenblatt, the 30-year-old architect of the project, was reaching beyond his training in experimental psychology to build a computer meant to rival the most advanced technology at the time.</p><a id="page_60"/>
<p class="TXI">The computer in question was taller than the engineers who operated it and about twice as long. It was covered on either end in various control panels and readout mechanisms. Rosenblatt requested the services of three ‘professional people’ and an associated technical staff for 18 months to build it, and the estimated cost was $100,000 (around $870,000 today). The word ‘perceptron’, defined by Rosenblatt, is a generic term for a certain class of devices that can ‘recognise similarities or identities between patterns of optical, electrical or tonal information’. The Perceptron – the computer that was built in 1958 – was thus technically a subclass known as a ‘photoperceptron’ because it took as its input the output of a camera mounted on a tripod at one end of the machine. </p>
<p class="TXI">The Perceptron was, just like the models introduced in the McCulloch-Pitts paper, an artificial neural network. It was a simplified replica of what real neurons do and how they connect to each other. But rather than remaining a mathematical construct that exists only as the ink of equations on a page, the Perceptron was physically realised. The camera provided 400 inputs to this network in the form of a 20x20 grid of light sensors. Wires then randomly connected the output of these sensors to 1,000 ‘association units’ – small electrical circuits that summed up their inputs and switched to ‘on’ or ‘off’ as a result, just like a neuron. The output of these association units became the input to the ‘response units’, which themselves could be ‘on’ or ‘off’. The number of response units was equal to the number of mutually exclusive categories to which an image could belong. So, if the Navy wanted to use the Perceptron, say, to <a id="page_61"/>determine if a jet was present in an image or not, there would be two response units: one for jet and one for no jet. At the end of the machine opposite the camera was a set of light bulbs that let the engineer know which of the response units was active – that is, which category the input belonged to. </p>
<p class="TXI">Implementing an artificial neural network this way was large and cumbersome, full of switches, plugboards and gas tubes. The same network made up of real neurons would be smaller than a grain of sea salt. But achieving this physical implementation was important. It meant that theories of how neurons compute could actually be tested in the real world on real data. Whereas the McCulloch-Pitts work was about proving a point in theory, the Perceptron put it into practice. </p>
<p class="TXI">Another important difference between the Perceptron and the McCulloch-Pitts network was that, as Rosenblatt told the <span class="italic">New York Times</span>, the Perceptron learns. In the McCulloch and Pitts paper, the authors make no reference to how the connectivity between the neurons comes to be. It is simply defined according to what logical function the network needs to carry out and it stays that way. For the Perceptron to learn, however, it must modify its connections.<sup><a href="#fn-4" id="fnt-4">4</a>
</sup> In fact, the Perceptron derives all its functionality from changing its connection strengths until they are just right. </p>
<p class="TXI">The type of learning the Perceptron engages in is known as ‘supervised’ learning. By providing pairs of inputs and outputs – say, a series of pictures and whether <a id="page_62"/>they each contain a jet or not – the Perceptron learns to make this decision on its own. It does so by changing the strength of the connections – also known as the ‘weights’ – between the association units and the readouts. </p>
<p class="TXI">Specifically, when an image is provided to the network, it activates units first in the input layer, then in the association layer, and finally in the readout layer, indicating the network’s decision. If the network gets the classification wrong, the weights change according to these rules:</p>
<p class="NLF">1. If a readout unit is ‘off’ when it should be ‘on’, the connections from the ‘on’ association units to that readout unit are <span class="italic">strengthened</span>.</p>
<p class="NLL">2. If a readout unit is ‘on’ when it should be ‘off’, the connections from the ‘on’ association units to that readout unit are <span class="italic">weakened</span>.</p>
<p class="TXT">By following these rules, the network will start to correctly associate images with the category they belong to. If the network can learn to do this well, it will stop making errors and the weights will stop changing. </p>
<p class="TXI">This procedure for learning was, in many ways, the most remarkable part of the Perceptron. It was the conceptual key that could open all doors. Rather than needing to tell a computer exactly how to solve a problem, you need only show it some examples of that problem solved. This had the potential to revolutionise computing and Rosenblatt was not shy in saying so. He told the <span class="italic">New York Times</span> that Perceptrons would ‘be able to recognise people and call out their names’ and ‘to hear speech in one language and instantly translate it to <a id="page_63"/>speech or writing in another language’. He also added that ‘it would be possible to build Perceptrons that could reproduce themselves on an assembly line and which would be “conscious” of their existence’. This was a bold statement, to say the least, and not everyone was happy with Rosenblatt’s public bravado. But the spirit of the claim – that a computer that could learn would expedite the solving of almost any problem – rang true.</p>
<p class="TXI">The power of learning, however, came with a price. Letting the system decide its own connectivity effectively divorced these connections from the concept of Boolean operators. The network <span class="italic">could</span> learn the connectivity that McCulloch and Pitts had identified as required for ‘and’, ‘or’, <span class="italic">etc.</span> But there was no requirement that it does, nor any need to understand the system in this light. Furthermore, while the association units in the Perceptron machine were designed to be only ‘on’ or ‘off’, the learning rule doesn’t actually require that they be this way. In fact, the activity level of these artificial neurons could be any positive number and the rule would still work.<sup><a href="#fn-5" id="fnt-5">5</a>
</sup> This makes the system more flexible, but without a binary ‘on’-‘off’ response it makes it harder to map the activity of these units to the binary truth values of propositions. Compared with the crisp and clear logic of the McCulloch-Pitts networks, the Perceptron was an uninterpretable mess. But it worked. Interpretability was sacrificed for ability.</p> <a id="page_64"/>
<p class="TXI">The Perceptron machine and its associated learning procedure became a popular object of study in the burgeoning field of artificial intelligence. When it made the transition from a specific physical object (the Perceptron) to an abstract mathematical concept (the perceptron algorithm) the separate input and association layers were done away with. Instead, input units representing incoming data connected directly to the readout units and, through learning, these connections changed to make the network better at its task. How and what the perceptron in this simplified form could learn was studied from every angle. Researchers explored its workings mathematically using pen and paper, or physically by building their own perceptron machines, or – when digital computers finally became available – electronically by simulating it.</p>
<p class="TXI">The perceptron generated hope that humans could build machines that learn like we do; in this way it put the prospect of artificial intelligence within 
reach. Simultaneously, it provided a new way of understanding our own intelligence. It showed that artificial neural networks could compute without abiding by the strict rules of logic. If the perceptron could perceive without the use of propositions or operators, it follows that each neuron and connection in the brain needn’t have a clear role in terms of Boolean logic either. Instead, the brain could be working in a sloppier way, wherein, like the perceptron, the function of a network is distributed across its neurons and emerges out of the connections between them. This new approach to the study of the brain became known as ‘connectionism’.</p> <a id="page_65"/>
<p class="TXI">The work of McCulloch and Pitts was an important stepping stone. As the first demonstration of how networks of neurons could think, it was responsible for getting neuroscience away from the shores of pure biology and into the sea of computation. This fact, rather than the veracity of its claims, is what earns it its place in history. The intellectual ancestor of McCulloch and Pitts’ work, the <span class="italic">Principia Mathematica</span>, could be said to have suffered a similar fate. In 1931, German mathematician Kurt Gödel published ‘On formally undecidable propositions of <span class="italic">Principia Mathematica</span> and related systems’. This paper took the <span class="italic">Principia Mathematica</span> as a starting point to show why its very goal – to explain all of mathematics from simple premises – was impossible to achieve. Russell and Whitehead had not, in fact, done what they believed they did.<sup><a href="#fn-6" id="fnt-6">6</a>
</sup> Gödel’s findings became known as the ‘incompleteness theorem’ and had a revolutionary effect on mathematics and philosophy. An effect that stemmed, in part, from Russell and Whitehead’s failed attempt.</p>
<p class="TXI">Russell and McCulloch were able to take the failings of their respective works in their stride. Pitts, on the other hand, was made of finer cloth. The realisation that the brain was not enacting the beautiful rules of logic tore him apart.<sup><a href="#fn-7" id="fnt-7">7</a>
</sup> This, along with pre-existing mental struggles and the end of a relationship with an important mentor, drove him to drink and experiment with other <a id="page_66"/>drugs. He became erratic and delirious; he burned his work and withdrew from his friends. He died from the impacts of liver disease in 1969 – the same year McCulloch died. McCulloch was 70; Pitts was 46. </p>
<p class="TXI">* * *</p>
<p class="image-fig" id="fig5.jpg">
<img alt="" src="../images/fig5.jpg"/></p>
<p class="FC"> 
<span class="bold">
<span class="italic">Figure 5</span>
</span></p>
<p class="TXI">The cerebellum is a forest. Folded up neatly near where the spinal cord enters the skull, this bit of the brain is thick with different types of neurons, like different species of trees, all living in chaotic harmony (see Figure 5). The Purkinje cells are large, easily identified and heavily branched: from the body of these cells, dendrites stretch up and away, like a thousand alien hands raised in prayer. The granule cells are numerous and small – with cell bodies less than half the size of the Purkinje’s – but their reach is far. Their axons initially grow upwards, in parallel with the Purkinje cells’ dendrites. They then make a sharp right turn to run directly through the branches of the Purkinje cells, like power lines through treetops. This is where the granule cells make contact with the Purkinje cells: each Purkinje cell gets input from hundreds of <a id="page_67"/>thousands of granule cells. Climbing fibres are axons that follow a longer path on their way to the Purkinje cells. These axons come from cells in a different brain region – the inferior olive – from which they navigate all the way to the bottom of the Purkinje cell bodies and creep up around them. Winding their way around the base of the Purkinje cell dendrites like ivy, the climbing fibres form connections. Unlike the granule cells, only a single climbing fibre targets each Purkinje cell. In the cerebellar landscape, Purkinje cells are thus central. They have scores of granule cells imposing on them from the top and a small yet precise set of climbing fibres closing in on them from the bottom. </p>
<p class="TXI">In its twisty, organic way, the circuitry of the cerebellum possesses an organisation and precision unbefitting of biology. It was in this biological wiring that James Albus, a PhD student in electrical engineering working at NASA, saw the principles of the perceptron at play. </p>
<p class="TXI">The cerebellum plays a crucial role in motor control; it helps with balance, coordination, reflexes and more. One of the most widely studied of its abilities is eye-blink conditioning. This is a trained reflex that can be found in everyday life. For example, if a determined parent or roommate tries to get you out of bed in the morning by pulling open the curtains, you’ll instinctively close your eyes in response to the sunlight. After a few days of this, simply the sound of the curtains being opened may be enough to make you blink in anticipation. </p>
<p class="TXI">In the lab, this process is studied in rabbits and the intruding sunlight is replaced by a small puff of air on the eye (just annoying enough to ensure they’ll want to avoid it). After several trials of playing a sound (such as a <a id="page_68"/>short blip of a pure tone) and following it by this little air puff, the rabbit eventually learns to close its eyes immediately upon hearing the tone. Play the animal a new sound (for example, a clapping noise) that hasn’t been paired with air puffs and it won’t blink. This makes eye-blink conditioning a simple classification task: the rabbit has to decide if a sound it hears is indicative of an upcoming air puff (in which case the eyes should close) or if it is a neutral noise (in which case they can remain open). Disrupt the cerebellum and rabbits can’t learn this task. </p>
<p class="TXI">The Purkinje cells have the power to close the eyes. Specifically, a dip in their normally high firing rate will, via connections the Purkinje cells send out of this area, cause the eyes to shut. Based on this anatomy, Albus saw their place as the readout – that is, they indicate the outcome of the classification. </p>
<p class="TXI">The perceptron learns via supervision: it needs inputs and labels for those inputs to know when it has erred. Albus saw these two functions in the two different types of connections on to Purkinje cells. The granule cells pass along sensory signals; specifically, different granule cells fire depending on which sound is being played. The climbing fibres tell the cerebellum about the air puff; they fire when this annoyance is felt. Importantly, this means the climbing fibres signal an error. They indicate that the animal made a mistake in not closing its eyes when it should have. </p>
<p class="TXI">To prevent this error, the connections from the granule cells to the Purkinje cells need to change. In particular, Albus anticipated that any granule cells that were active before the climbing fibre was active (<span class="italic">i.e.</span>, before an error), <a id="page_69"/>should weaken their connection to the Purkinje cell. That way, the next time those granule cells fire – <span class="italic">i.e.</span>, the next time the same sound is played – they <span class="italic">won’t</span> cause firing in the Purkinje cells. And that dip in Purkinje cell firing <span class="italic">will</span> cause the eyes to close. Through this changing of connection strengths, the animal learns from its past mistakes and avoids future air puffs to the eye.</p>
<p class="TXI">In this way, the Purkinje cell acts like a president advised by a cabinet of granule cell advisors. At first the Purkinje cell listens to all of them. But if it’s clear that some are providing bad advice – that is, their input is followed by negative news delivered by the climbing fibre – their influence over the Purkinje cell will fade. And the Purkinje cell will act better in the future. It is a process that directly mirrors the perceptron learning rule.</p>
<p class="TXI">When Albus proposed this mapping between the perceptron and the cerebellum in 1971,<sup><a href="#fn-8" id="fnt-8">8</a>
</sup> his prediction about how the connections between granule cells and Purkinje cells should change was just that – a prediction. No one had directly observed this kind of learning in the cerebellum. But by the mid-1980s, evidence had piled up in Albus’ favour. It became clear that the strength of the connection between a granule cell and a Purkinje cell does decrease after an error. The particular molecular mechanisms of this process have even been revealed. We now know that granule cell inputs cause a receptor in <a id="page_70"/>the membrane of the Purkinje cell to respond, effectively tagging which granule cell inputs were active at a given time. If a climbing fibre input comes later (during an air puff), it causes calcium to flood into the Purkinje cell. The presence of this calcium signals to all the tagged connections to decrease their strength. Patients with fragile X syndrome – a genetic disorder that leads to intellectual disabilities – appear to be missing a protein that regulates this connection from the granule cells on to the Purkinje cell. As a result, they have trouble learning tasks like eye-blink conditioning. </p>
<p class="TXI">The perceptron, with its explicit rules of how learning should proceed in a neural network, offered clear testable ideas for neuroscientists to hunt for – and find – in the brain. In doing so, it was able to connect science across scales. The smallest physical detail – calcium ions moving through the inside of a neuron, for example – inherits a much larger meaning in light of its role in computation. </p>
<p class="center">* * *</p>
<p class="TXT">The reign of the perceptron was cut short in 1969. And with a twist of Shakespearean irony, it was its namesake that killed it. </p>
<p class="TXI">
<span class="italic">Perceptrons</span> was written by Marvin Minsky and Seymour Papert, both mathematicians at the Massachusetts Institute of Technology. The book was subtitled <span class="italic">An Introduction to Computational Geometry</span> and had a simple abstract design on the cover. Minsky and Papert were drawn to write about the topic of perceptrons out of appreciation for Rosenblatt’s invention and a desire to explore it further. <a id="page_71"/>In fact, Minsky and Papert met at a conference where they were presenting similar results from their explorations into how the perceptron learns. </p>
<p class="TXI">Papert was a native of South Africa with full cheeks, a healthy beard and not one, but <span class="italic">two</span>, PhDs in mathematics. He had a lifelong interest in education and how it could be transformed by computing. Minsky was less than a year older than Papert, with sharper features and large glasses. A New York native, he attended the Bronx High School of Science with Frank Rosenblatt; he was also mentored by McCulloch and Pitts. </p>
<p class="TXI">Minsky and Papert shared with McCulloch and Pitts the compulsive desire to formalise thinking. True advances in understanding computation, they believed, came from mathematical derivations. All the empirical success of the perceptron – whatever computing it was able to carry out or categories it was able to learn – meant next to nothing without a mathematical understanding of why and how it worked. </p>
<p class="TXI">At this time, the perceptron was attracting a lot of attention – and money – from the artificial intelligence community. But it wasn’t attracting the kind of mathematical scrutiny Minsky and Papert yearned for. The two were thus explicitly motivated to write their book by a desire to increase the rigour around the study of perceptrons – but also, as Papert later acknowledged, by some desire to decrease the reverence for them.<sup><a href="#fn-9" id="fnt-9">9</a>
</sup></p>
<p class="TXI">The pages of <span class="italic">Perceptrons</span> are comprised mainly of proofs, theorems and derivations. Each contributes to a <a id="page_72"/>story about the perceptron: defining what it is, what it can do and how it learns. Yet from the publication of these some 200 pages – a thorough exploration of the ins and outs of the perceptron’s workings – the message the community received was largely about its limitations. This is because Minsky and Papert had shown, conclusively, that certain simple computations were impossible for the perceptron to do. </p>
<p class="TXI">Consider a perceptron that has just two inputs, and each input can be ‘on’ or ‘off’. We want the perceptron to report if the two inputs are the same: to respond yes (<span class="italic">i.e.</span>, have its readout unit be on) if both inputs are on <span class="italic">or</span> if both inputs are off. But if one is on and the other is off, the readout unit should be off. Like sorting socks out of the laundry, the perceptron should only respond when it sees a matching pair.</p>
<p class="TXI">To make sure the readout doesn’t fire when only one input is on, the weights from each input need to be sufficiently low. They could, for example, each be half the amount needed to make the readout turn on. This way, when both are on, the readout <span class="italic">will</span> fire and it won’t fire when only one input is on. In this setup the readout is responding correctly for three of the four possible input conditions. But in the condition where both inputs are off, the readout will be off – an incorrect classification. </p>
<p class="TXI">As it turns out, no matter how much we fiddle with connection strengths, there is no way to satisfy all the needs of the classification at once. The perceptron simply cannot do it. And the problem with that is that no good model of the brain – or promising artificial intelligence – should fail at a task as simple as deciding if two things are the same or not.</p> <a id="page_73"/>
<p class="TXI">Albus, whose paper on the cerebellum was published in 1971, knew of the limitations of the perceptron and knew that, despite these limitations, it was still powerful enough to be a model of the eye-blink conditioning task. But a model of the whole human brain, as Rosenblatt promised? Not possible.</p>
<p class="TXI">The portrait that Minsky and Papert painted forced researchers to see the perceptron’s powers clearly. Prior to the book, researchers were able to explore what the perceptron could do blindly, with the hope that the limits of its abilities were still far off, if they existed at all. Once the contours were put in stark relief, however, there was no denying that these boundaries existed, and that they existed much closer than expected. In truth, all this amounted to was an understanding of the perceptron – exactly what Minsky and Papert set out to do. But the end of ignorance around the perceptron meant the end of excitement around it as well. As Papert put it: ‘Being understood can be a fate as bad as death.’</p>
<p class="TXI">The period that followed the publication of <span class="italic">Perceptrons</span> is known as the ‘dark ages’ of connectionism. It was marked by significant decreases in funding to the research programmes that had grown out of Rosenblatt’s initial work. The neural network approach to building artificial intelligence was snuffed out. All the excessive promises, hopes and hype had to be retracted. Rosenblatt himself died tragically in a boating accident two years after the book was published and the field he helped build remained dormant for more than 10 years.</p>
<p class="TXI">But if the hype around the perceptron was excessive and ill informed, so too was the backlash against it. The limitations in Minsky and Papert’s book were true: the <a id="page_74"/>perceptron in the form they were studying it was incapable of many things. But it didn’t need to keep that form. The same-or-not problem, for example, could be easily solved by adding an additional layer of neurons between the input and the readout. This layer could be composed of two neurons, one with weights that make it fire when both inputs are on and the other with weights that make it fire when both inputs are off. Now the readout neuron, which gets its input from these middle neurons, just needs to be active if one of the middle neurons is active. </p>
<p class="TXI">‘Multi-layer perceptrons’, as these new neural architectures were called, had the potential to bring connectionism back from the dead.<sup><a href="#fn-10" id="fnt-10">10</a>
</sup> But before a full resurrection was possible, one problem had to be solved: learning. The original perceptron algorithm provided the recipe for setting the connections between the input neurons and the readout neurons – that is, the learning rule was designed for a two-layered network. If the new breed of neural networks was going to have three, four, five or more layers, how should the connections between all those layers be set? (see Figure 6) Despite all the good features of the perceptron learning rule – its simplicity, the proof that it could work, the fact that it had been spotted in the wild of the cerebellum – it was unable to answer this question. Knowing that a multi-layer perceptron <span class="italic">could</span> solve more complex problems was not enough to deliver <a id="page_75"/>on the grand promises of connectionism. What was needed was for it to <span class="italic">learn</span> to solve those problems.</p>
<p class="center">* * *</p>
<p class="TXT">The Easter Sunday of the connectionist revival story came in 1986. The paper ‘Learning representations by back-propagating errors’, written by two cognitive scientists from the University of California San Diego, David Rumelhart and Ronald Williams, and a computer scientist from Carnegie Mellon, Geoffrey Hinton, was published on 9 October in the journal <span class="italic">Nature</span>. It presented a solution to the exact problem the field had: how to train multi-layer artificial neural networks. The learning algorithm in the paper, called ‘backpropagation’, became widely used by the community at the time. And it remains to this day the dominant way in which artificial neural networks are trained to do interesting tasks.</p>
<p class="image-fig" id="fig6.jpg">
<img alt="" src="../images/fig6.jpg"/></p>
<p class="FC"> 
<span class="bold">
<span class="italic">Figure 6</span>
</span></p>
<p class="TXI">The original perceptron’s learning rule works because, with only two layers, it’s easy to see how to fix what’s gone wrong. If a readout neuron is off when it should be on, connections going from the input layer to that neuron <a id="page_76"/>need to get stronger and vice versa. The relationship between these connections and the readout is thus clear. The backpropagation algorithm has a more difficult problem to solve. In a network with many layers between the input and readout, the relationships between all these connections and the readout aren’t as clear. Now instead of a president and his or her advisors, we have a president, their advisors, and the employees of those advisors. The amount of trust an advisor has in any given employee – <span class="italic">i.e.</span>, the strength of the connection from that employee to the advisor – will certainly have an impact, ultimately, on what the president does. But this impact is harder to directly see and harder to fix if the president feels something is going wrong. </p>
<p class="TXI">What was needed was an explicit way to calculate how any connection in the network would impact the readout layer. As it turns out, mathematics offers a neat way to do this. Consider an artificial neural network with three layers: input, middle and readout. How do the connections from the input to the middle layer impact the readout? We know the activity of the middle layer is a result of the activities of the input neurons and the weights of their connections to the middle layer. With this knowledge, writing an equation for how these weights affect the activity at the middle layer is straightforward. We also know that the readout neurons follow the same rule: their activity is determined by the activities of the middle neurons and the weights connecting the middle neurons to the readout. Therefore, an equation describing how these weights impact the readout is also easy to get. The only thing left to do is find a way to string these two equations together. That <a id="page_77"/>way we’ll have an equation that tells us directly how the connections from the input to the middle layer impact the readout. </p>
<p class="TXI">When forming a train in the game of dominoes, the number on the end of one tile needs to match the number on the start of another in order for them to connect. The same is true for stitching together these equations. Here, the common term that connects the two equations is the activity of the middle layer: this activity both determines the activity of the readout and is determined by the input-to-middle connections. After joining these equations via the middle layer activity, the impact of the input-to-middle layer connections on the readout can be calculated directly. And this makes it easy to figure out how those connections should change when the readout is wrong. In calculus, this linking together of relationships is known as the ‘chain rule’ and it is the core of the backpropagation algorithm. </p>
<p class="TXI">The chain rule was discovered over 200 years ago by none other than the idol of McCulloch and Pitts, philosopher and polymath Gottfried Leibniz. Given how useful the rule is, its application to the training of multi-layer neural networks was no surprise. In fact, the backpropagation algorithm appears to have been invented at least three separate times before 1986. But the 1986 paper was part of a perfect storm that ensured its findings would spread far and wide. The first reason for this was the content of the paper itself. Not only did it show that neural networks could be trained this way, it also analysed the workings of networks trained on several cognitive tasks, such as understanding relations on a family tree. Another component of the success was the <a id="page_78"/>increase in computational power that came in the 1980s; this was important for making the training of multi-layer neural networks practically possible for researchers. Finally, the same year the paper was published, one of its authors, Rumelhart, also published a book on connectionism that included the backpropagation algorithm. That book – written with a different Carnegie Mellon professor, James McClelland – went on to sell an estimated 40,000 copies by the mid-1990s. Its title, <span class="italic">Parallel Distributed Processing</span>, lent its name to the entire research agenda of building artificial neural networks in the late 1980s and early 1990s. </p>
<p class="TXI">For somewhat similar reasons, the story of artificial neural networks took an even more dramatic turn roughly a decade into the new millennium. The heaps of data accumulated in the internet age united with the computational power of the twenty-first century to supercharge progress in this field. Networks with more and more layers could suddenly be trained on more and more complex tasks. Such scaled-up models – referred to as ‘deep neural networks’ – are currently transforming artificial intelligence and neuroscience alike. </p>
<p class="TXI">The deep neural networks of today are based on the same basic understanding of neurons as those of McCulloch and Pitts. Beyond that base inspiration, though, they don’t aim to directly replicate the human brain. They aren’t trying to mimic its structure or anatomy, for example.<sup><a href="#fn-11" id="fnt-11">11</a>
</sup> But they do aim to mimic human behaviour and they’re getting quite good at it. When <a id="page_79"/>Google’s popular language translation service started using a deep neural network approach in 2016, it reduced translation errors by 50 per cent. YouTube also uses deep neural networks to help its recommendation algorithm better understand what videos people want to see. And when Apple’s voice assistant Siri responds to a command, it is a deep neural network that is doing the listening and the speaking. </p>
<p class="TXI">In total, deep neural networks can now be trained to find objects in images, play games, understand preferences, translate between different languages, turn speech into written words and turn written words into speech. Not unlike the original Perceptron machine, the computers these networks run on fill up rooms. They’re located in server centres across the globe, where they hum away processing the world’s image, text and audio data. Rosenblatt may have been pleased to see that some of his grand promises to the <span class="italic">New York Times</span> were indeed fulfilled. They just required a scale nearly a thousand times what he had available at the time. </p>
<p class="TXI">The backpropagation algorithm was necessary to boost artificial neural networks to the point where they could reach near-human levels of performance on some tasks. As a learning rule for neural networks, it really works. Unfortunately, that doesn’t mean it works like the brain. While the perceptron learning rule was something that could be seen at play between real neurons, the backpropagation algorithm is not. It was designed as a mathematical tool to make artificial neural networks work, not a model of how the brain learns (and its inventors were very clear on that from the start). The reason for this is that real neurons can typically only <a id="page_80"/>know about the activity of the neurons they’re connected to – not about the activity of the neurons those neurons connect to and so on and so on. For this reason, there is no obvious way for real neurons to implement the chain rule. They must be doing something different. </p>
<p class="TXI">For some researchers – particularly researchers in the field of artificial intelligence – the artificial nature of backpropagation is no problem. Their goal is to build computers that can think, by whatever means necessary. But for other scientists – neuroscientists in particular – finding the learning algorithm of the brain is paramount. We know the brain is good at getting better; we see it when we learn a musical instrument, how to drive or how to read a new language. The question is how.</p>
<p class="TXI">Because backpropagation is what we know works, some neuroscientists are starting there. They’re checking for signs that the brain is doing something <span class="italic">like</span> backpropagation, even if it can’t do it exactly. Inspiration comes from the success story of finding a perceptron at work in the cerebellum. There, clues were present in the anatomy; the different placement of the climbing fibres and granule cells pointed to a different role for each. Other brain areas display patterns of connectivity which may hint at how they are learning. For example, in the neocortex, some neurons have dendrites that stretch out way above them. Faraway regions of the brain send inputs to these dendrites. Do they carry with them information about how these neurons have impacted those that come after them in the brain’s neural network? Could this information be used to change the strength of the network’s connections? Both neuroscientists and artificial intelligence researchers hold out hope that the <a id="page_81"/>brain’s version of backpropagation will be found and that, when it is, it can be copied to create algorithms that learn even better and faster than today’s artificial neural networks. </p>
<p class="TXI">In their hunt to understand how the mind learns from supervision, modern researchers are doing just what McCulloch did. They’re looking at the piles of facts we have about the biology of the brain and trying to see in it a computational structure. Today, they are guided in their search by the workings of artificial systems. Tomorrow, the findings from biology will again guide the building of artificial intelligence. This back-and-forth defines the symbiotic relationship between these two fields. Researchers looking to build artificial neural networks can take inspiration from the patterns found in biological ones, while neuroscientists can look to the study of artificial intelligence to identify the computational role of biological details. In this way, artificial neural networks keep the study of the mind and the brain connected.</p>
<p class="H1">Notes</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-1" id="fn-1">1</a> ﻿Named after the English mathematician George Boole. While they used his ideas, Russell and Whitehead didn﻿’﻿t actually use the term ﻿‘﻿Boolean﻿’﻿, as it wasn﻿’﻿t coined until 1913.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-2" id="fn-2">2</a> ﻿At least that﻿’﻿s what it looked like at the time ﻿…﻿ More on this later.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-3" id="fn-3">3</a> ﻿The use of the word ﻿‘﻿circuit﻿’﻿ here differs from that in the last chapter. In addition to its meaning as an electrical circuit, neuroscientists also use the word to refer to a group of neurons connected in a specific way. ﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-4" id="fn-4">4</a> ﻿More on how learning ﻿–﻿ and memory ﻿–﻿ relies on a change in connections in the next chapter.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-5" id="fn-5">5</a> ﻿This can be thought of as representing the ﻿<span class="italic">rate</span>﻿ of spiking of a neuron, rather than if the neuron is emitting a spike or not. Using this type of artificial neuron only requires a small modification to the learning procedure.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-6" id="fn-6">6</a> ﻿The cracks in the ﻿<span class="italic">Principia</span>﻿﻿’﻿s foundation were noticeable even when it was published. Some of the ﻿‘﻿basic﻿’﻿ premises it had to assume were not really very basic and were hard to justify.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-7" id="fn-7">7</a> ﻿This realisation came even more directly from a study on the frog brain that Pitts was involved with. More on that study in ﻿﻿Chapter 6﻿﻿.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-8" id="fn-8">8</a> ﻿The mapping is sometimes referred to as the ﻿‘﻿Marr-Albus-Ito﻿’﻿ theory of motor learning, named also after David Marr and Masao Ito, who both put forth similar models of how the cerebellum learns. ﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-9" id="fn-9">9</a> ﻿The particular words Papert used to describe his feelings about Perceptron-mania at the time were ﻿‘﻿hostility﻿’﻿ and ﻿‘﻿annoyance﻿’﻿.﻿</p>
<p class="FN2"><a href="chapter3.xhtml#fnt-10" id="fn-10">10</a> ﻿Technically they weren﻿’﻿t ﻿‘﻿new﻿’﻿. Minsky and Papert do reference multi-layer perceptrons in their book. However, they were dismissive about the potential powers of these devices and, unfortunately for science, did not encourage their further study. ﻿</p>
<p class="FN2"><a href="chapter3.xhtml#fnt-11" id="fn-11">11</a> ﻿With the exception of deep neural networks that are built to understand images, which we will hear all about in ﻿﻿Chapter 6﻿﻿.﻿</p>
</body>
</html>