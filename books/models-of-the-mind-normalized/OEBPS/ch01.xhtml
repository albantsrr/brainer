<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML">
<head>
<title>Chapter 1</title>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000006607108" name="Adept.expected.resource"/>
</head>
<body>
<p class="CN" id="chapter1"><a href="contents.xhtml#re_chapter1">CHAPTER ONE</a></p>
<p class="CT"><a href="contents.xhtml#re_chapter1">Spherical Cows</a><a id="page_7"></a></p>
<p class="H1" id="b-9781472966445-ch58-sec1">
<span class="bold">
<span>What mathematics has to offer</span>
</span></p>
<p class="TXT">The web-weaving spider <span class="italic">Cyclosa octotuberculata</span> inhabits several locations in and around Japan. About the size of a fingernail and covered in camouflaging specks of black, white and brown, this arachnid is a crafty predator. Sitting at the hub of its expertly built web, it waits to feel vibrations in the web’s threads that are caused by struggling prey. As soon as the spider senses this movement, it storms off in the direction of the signal, ready to devour its catch.</p>
<p class="TXI">Sometimes prey is more commonly found in one location on the web than others. Smart predators know to keep track of these regularities and exploit them. Certain birds, for example, will recall where food has been abundant recently and return to those areas at a later time. <span class="italic">Cyclosa octotuberculata</span> does something similar – but not identical. Rather than remembering the locations that have fared well – that is, rather than storing these locations in its mind and letting them influence its future attention – the spider literally weaves this information into its web. In particular, it uses its legs to tug on the specific silk threads from which prey has recently been detected, making them tighter. The tightened threads are more sensitive to vibrations, making future prey easier to detect on them.</p><a id="page_8"></a>
<p class="TXI">Making these alterations to its web, <span class="italic">Cyclosa octotuberculata</span> offloads some of the burden of cognition to its environment. It expels its current knowledge and memory into a compact yet meaningful physical form, making a mark on the world that can guide its future actions. The interacting system of the spider and its web is smarter than the spider could hope to be on its own. This outsourcing of intellect to the environment is known as ‘extended cognition’. </p>
<p class="TXI">Mathematics is a form of extended cognition.</p>
<p class="TXI">When a scientist, mathematician or engineer writes down an equation, they are expanding their own mental capacity. They are offloading their knowledge of a complicated relationship on to symbols on a page. By writing these symbols down, they leave a trail of their thinking for others and for themselves in the future. Cognitive scientists hypothesise that spiders and other small animals rely on extended cognition because their brains are too limited to do all the complex mental tasks required to thrive in their environment. We are no different. Without tools like mathematics our ability to think and act effectively in the world is severely limited. </p>
<p class="TXI">Mathematics makes us better in some of the same ways written language does. But mathematics goes beyond everyday language because it is a language that can do real work. The mechanics of mathematics – the rules for rearranging, substituting and expanding its symbols – are not arbitrary. They are a systematic way to export the process of thinking to paper or machines. Alfred Whitehead, a revered twentieth-century mathematician whose work we will encounter in <a href="chapter3.xhtml#chapter3">Chapter 3</a>, has been paraphrased as saying: ‘The ultimate <a id="page_9"></a>goal of mathematics is to eliminate any need for intelligent thought.’ </p>
<p class="TXI">Given this useful feature of mathematics, some scientific subjects – physics chief among them – have developed an ethos centred on rigorous quantitative thinking. Scientists in these fields have capitalised on the power of mathematics for centuries. They know that mathematics is the only language precise and efficient enough to describe the natural world. They know that the specialised notation of equations expertly compresses information, making an equation like a picture: it can be worth a thousand words. They also know that mathematics keeps scientists honest. When communicating through the formalism of mathematics, assumptions are laid bare and ambiguities have nowhere to hide. In this way, equations force clear and coherent thinking. As Bertrand Russell (a colleague of Whitehead whom we will also meet in <a href="chapter3.xhtml#chapter3">Chapter 3</a>) wrote: ‘Everything is vague to a degree you do not realise till you have tried to make it precise.’ </p>
<p class="TXI">The final lesson that quantitative scientists have learnt is that the beauty of mathematics lies in its ability to be both specific and universal. An equation can capture exactly how the pendulum in the barometrical clock on the Ministers’ Landing at Buckingham Palace will swing; the very same equation describes the electrical circuits responsible for broadcasting radio stations around the world. When an analogy exists between underlying mechanisms, equations serve as the embodiment of that analogy. As an invisible thread tying together disparate topics, mathematics is a means by which advances in one field can have surprising and disproportionate impacts on other, far-flung areas.</p><a id="page_10"></a>
<p class="TXI">Biology – including the study of the brain – has been slower to embrace mathematics than some other fields. A certain portion of biologists, for reasons good and bad, have historically eyed mathematics with some scepticism. In their opinion, mathematics is both too complex and too simple to be of much use.</p>
<p class="TXI">Some biologists find mathematics too complex because – trained as they are in the practical work of performing lab experiments and not in the abstract details of mathematical notion – they see lengthy equations as meaningless scribble on the page. Without seeing the function in the symbols, they’d rather do without them. As biologist Yuri Lazebnik wrote in a 2002 plea for more mathematics in his field: ‘In biology, we use several arguments to convince ourselves that problems that require calculus can be solved with arithmetic if one tries hard enough and does another series of experiments.’</p>
<p class="TXI">Yet mathematics is also considered too simple to capture the overwhelming richness of biological phenomena. An old joke among physicists highlights the sometimes absurd level of simplification that mathematical approaches can require. The joke starts with a dairy farmer struggling with milk production. After trying everything he could think to get his beloved cows to produce more, he decides to ask the physicist at the local university for help. The physicist listens carefully to the problem and goes back to his office to think. After some consideration, he comes back to the farmer and says: ‘I found a solution. First, we must assume a spherical cow in a vacuum … ’ </p>
<p class="TXI">Simplifying a problem is what opens it up to mathematical analysis, so inevitably some biological details get lost in <a id="page_11"></a>translation from the real world to the equations. As a result, those who use mathematics are frequently disparaged as being too disinterested in those details. In his 1897 book <span class="italic">Advice for a Young Investigator</span>, Santiago Ramón y Cajal (the father of modern neuroscience whose work is discussed in <a href="chapter9.xhtml#chapter9">Chapter 9</a>) wrote about these reality-avoiding theorists in a chapter entitled ‘Diseases of the Will’. He identified their symptoms as ‘a facility for exposition, a creative and restless imagination, an aversion to the laboratory, and an indomitable dislike for concrete science and seemingly unimportant data’. Cajal also lamented the theorist’s preference for beauty over facts. Biologists study living things that are abundant with specific traits and nuanced exceptions to any rule. Mathematicians – driven by simplicity, elegance and the need to make things manageable – squash that abundance when they put it into equations. </p>
<p class="TXI">Oversimplification and an obsession with aesthetics are legitimate pitfalls to avoid when applying mathematics to the real world. Yet, at the same time, the richness and complexity of biology is exactly why it needs mathematics.</p>
<p class="TXI">Consider a simple biological question. There are two types of animals in a forest: rabbits and foxes. Foxes eat rabbits, rabbits eat grass. If the forest starts off with a certain number of foxes and a certain number of rabbits, what will happen to these two populations? </p>
<p class="TXI">Perhaps the foxes ferociously gobble up the rabbits, bringing them to extinction. But then the foxes, having exhausted their food source, will starve and die off themselves. This leaves us with a rather empty forest. On the other hand, maybe the fox population isn’t so <a id="page_12"></a>ravenous. Perhaps they reduce the rabbit population to almost zero but not quite. The fox population still plummets as each individual struggles to find the remaining rabbits. But then – with most of the foxes gone – the rabbit population can rebound. Of course, now the food for the foxes is abundant again and, if enough of their population remains, they too can resurge.</p>
<p class="TXI">When it comes to knowing the outcome for the forest, there is a clear limitation to relying on intuition. Trying to ‘think through’ this scenario, as simple as it is, using just words and stories is insufficient. To make progress, we must define our terms precisely and state their relationships exactly – and that means we’re doing mathematics. </p>
<p class="TXI">In fact, the mathematical model of predator–prey interactions that can help us here is known as the Lotka–Volterra model and it was developed in the 1920s. The Lotka-Volterra model consists of two equations: one that describes the growth of the prey population in terms of the numbers of prey and predators, and another that describes the growth of the predator population in terms of the numbers of predators and prey. Using dynamical systems theory – a set of mathematical tools initially forged to describe the interactions of celestial bodies – these equations can tell us whether the foxes will eventually die off, or the rabbits will, or if they’ll carry on in this dance together forever. In this way, the use of mathematics makes us better at understanding biology. Without it, we are sadly limited by our own innate cognitive talents. As Lazebnik wrote: ‘Understanding 
[a complex] system without formal analytical tools requires geniuses, who are so rare even outside biology.’</p><a id="page_13"></a>
<p class="TXI">To look at a bit of biology and see how it can be reduced to variables and equations requires creativity, expertise and discernment. The scientist must see through the messy details of the real world and find the bare-bones structure that underlies it. Each component of their model must be defined appropriately and exactly. Once a structure is found and an equation written, however, the fruits of this discipline are manifest. Mathematical models are a way to describe a theory about how a biological system works precisely enough to communicate it to others. If this theory is a good one, the model can also be used to predict the outcomes of future experiments and to synthesise results from the past. And by running these equations on a computer, models provide a ‘virtual laboratory’, a way to quickly and easily plug in different values to see how different scenarios may turn out and even perform ‘experiments’ not yet feasible in the physical world. By working through scenarios and hypotheses digitally this way, models help scientists determine what parts of a system are important to its function and, importantly, which are not. </p>
<p class="TXI">Such integral work could hardly be carried out using simple stories unaccompanied by mathematics. As Larry Abbott, a prominent theoretical neuroscientist and co-author<sup><a href="#fn-1" id="fnt-1">1</a>
</sup> of one of the most widely used textbooks on the subject, explained in a 2008 article:</p>
<p class="EXT">
<span class="italic">Equations force a model to be precise, complete and self-consistent, and they allow its full implications to be worked out. It is not difficult to find word models in the conclusions sections of older <a id="page_14"></a>neuroscience papers that sound reasonable but, when expressed as mathematical models, turn out to be inconsistent and unworkable. Mathematical formulation of a model forces it to be self-consistent and, although self-consistency is not necessarily truth, self-inconsistency is certainly falsehood.</span></p>
<p class="TXT">The brain – composed of (in the case of humans) some 100 billion neurons, each their own bubbling factory of chemicals and electricity, all interacting in a jumble of ways with their neighbours both near and far – is a prime example of a biological object too complex to be understood without mathematics. The brain is the seat of cognition and consciousness. It is responsible for how we feel, how we think, how we move, who we are. It is where days are planned, memories are stored, passions are felt, choices are made, words are read. It is the inspiration for artificial intelligence and the source of mental illness. To understand how all this can be accomplished by a single complex of cells, interfacing with a body and the world, demands mathematical modelling at multiple levels. </p>
<p class="TXI">Despite the hesitancy felt by some biologists, mathematical models can be found hidden in all corners of the history of neuroscience. And while it was traditionally the domain of adventurous physicists or wandering mathematicians, today ‘theoretical’ or ‘computational’ neuroscience is a fully developed subdivision of the neuroscience enterprise with dedicated journals, conferences, textbooks and funding sources. The mathematical mindset is influencing the whole of the study of the brain. As Abbott wrote: ‘Biology used to be a refuge for students fleeing mathematics, but now many <a id="page_15"></a>life sciences students have a solid knowledge of basic mathematics and computer programming, and those that don’t at least feel guilty about it.’<sup><a href="#fn-2" id="fnt-2">2</a>
</sup> </p>
<p class="TXI">Yet the biologist’s apprehension around mathematical models should not be entirely dismissed. ‘All models are wrong,’ starts the popular phrase by statistician George Box. Indeed, all models <span class="italic">are</span> wrong, because all models ignore some details. All models are also wrong because they represent only a biased view of the processes they claim to capture. And all models are wrong because they favour simplicity over absolute accuracy. All models are wrong the same way all poems are wrong; they capture an essence, if not a perfect literal truth. ‘All models are wrong but some are useful,’ says Box. If the farmer in the old joke reminded the physicist that cows are not, in fact, spherical, the physicist’s response would be, ‘Who cares?’, or more accurately, ‘Do we need to care?’. Detail for detail’s sake is not a virtue. A map the size of the city has no good use. The art of mathematical modelling is in deciding which details matter and steadfastly ignoring those that do not. </p>
<p class="TXI">This book charts the influence of mathematical thinking – borrowed from physics, engineering, statistics and computer science – on the study of the brain. Each chapter tells, for a different topic in neuroscience, the story of the biology, the mathematics and the interplay between the two. No special knowledge of mathematics is assumed <a id="page_16"></a>on the part of the reader; the ideas behind the equations will be explained.<sup><a href="#fn-3" id="fnt-3">3</a>
</sup> No single theory of the brain is being proposed; different models solve different problems and offer complementary approaches to understanding. </p>
<p class="TXI">The chapters are ordered from the low to the high level: from the physics of single cells up to the mathematics of behaviour. The stories in these chapters include the struggles encountered in unifying mathematics and biology, and the scientists who did the struggling. They show that sometimes experiments inform models and sometimes models inform experiments. They also show that a model can be anything from a few equations confined to a page to countless lines of code run on supercomputers. In this way, the book is a tapestry of the many forms mathematical models of the brain can take. Yet while the topics and models covered are diverse, common themes do reappear throughout the pages. </p>
<p class="TXI">Of course, everything in this book may be wrong. It may be wrong because it is science and our understanding of the world is ever-evolving. It may be wrong because it is history and there is always more than one way to tell a story. And, most importantly, it <span class="italic">is</span> wrong because it is mathematics. Mathematical models of the mind do not make for perfect replicas of the brain, nor should we strive for them to be. Yet in the study of the most complex object in the known universe, mathematical models are not just useful but absolutely essential. The brain will not be understood though words alone.</p>
<p class="H1">Notes</p>
<p class="FN1"><a href="chapter1.xhtml#fnt-1" id="fn-1">1</a> ﻿Along with Peter Dayan, whom we will meet in ﻿﻿Chapter 11﻿﻿.﻿</p>
<p class="FN1"><a href="chapter1.xhtml#fnt-2" id="fn-2">2</a> ﻿This guilt may not be entirely new. Charles Darwin, certainly a successful biologist, wrote in an 1887 autobiography: ﻿‘﻿I have deeply regretted that I did not proceed far enough at least to understand something of the great leading principles of mathematics, for men thus endowed seem to have an extra sense.﻿’﻿ ﻿</p>
<p class="FN1"><a href="chapter1.xhtml#fnt-3" id="fn-3">3</a> ﻿However, for the mathematically inclined, an appendix elaborating on one of the main equations per chapter is provided at the end of the book. ﻿</p>
</body>
</html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML">
<head>
<title>Chapter 1</title>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000006607108" name="Adept.expected.resource"/>
</head>
<body>
<p class="CN" id="chapter1"><a href="contents.xhtml#re_chapter1">CHAPTER ONE</a></p>
<p class="CT"><a href="contents.xhtml#re_chapter1">Spherical Cows</a><a id="page_7"></a></p>
<p class="H1" id="b-9781472966445-ch58-sec1">
<span class="bold">
<span>What mathematics has to offer</span>
</span></p>
<p class="TXT">The web-weaving spider <span class="italic">Cyclosa octotuberculata</span> inhabits several locations in and around Japan. About the size of a fingernail and covered in camouflaging specks of black, white and brown, this arachnid is a crafty predator. Sitting at the hub of its expertly built web, it waits to feel vibrations in the web’s threads that are caused by struggling prey. As soon as the spider senses this movement, it storms off in the direction of the signal, ready to devour its catch.</p>
<p class="TXI">Sometimes prey is more commonly found in one location on the web than others. Smart predators know to keep track of these regularities and exploit them. Certain birds, for example, will recall where food has been abundant recently and return to those areas at a later time. <span class="italic">Cyclosa octotuberculata</span> does something similar – but not identical. Rather than remembering the locations that have fared well – that is, rather than storing these locations in its mind and letting them influence its future attention – the spider literally weaves this information into its web. In particular, it uses its legs to tug on the specific silk threads from which prey has recently been detected, making them tighter. The tightened threads are more sensitive to vibrations, making future prey easier to detect on them.</p><a id="page_8"></a>
<p class="TXI">Making these alterations to its web, <span class="italic">Cyclosa octotuberculata</span> offloads some of the burden of cognition to its environment. It expels its current knowledge and memory into a compact yet meaningful physical form, making a mark on the world that can guide its future actions. The interacting system of the spider and its web is smarter than the spider could hope to be on its own. This outsourcing of intellect to the environment is known as ‘extended cognition’. </p>
<p class="TXI">Mathematics is a form of extended cognition.</p>
<p class="TXI">When a scientist, mathematician or engineer writes down an equation, they are expanding their own mental capacity. They are offloading their knowledge of a complicated relationship on to symbols on a page. By writing these symbols down, they leave a trail of their thinking for others and for themselves in the future. Cognitive scientists hypothesise that spiders and other small animals rely on extended cognition because their brains are too limited to do all the complex mental tasks required to thrive in their environment. We are no different. Without tools like mathematics our ability to think and act effectively in the world is severely limited. </p>
<p class="TXI">Mathematics makes us better in some of the same ways written language does. But mathematics goes beyond everyday language because it is a language that can do real work. The mechanics of mathematics – the rules for rearranging, substituting and expanding its symbols – are not arbitrary. They are a systematic way to export the process of thinking to paper or machines. Alfred Whitehead, a revered twentieth-century mathematician whose work we will encounter in <a href="chapter3.xhtml#chapter3">Chapter 3</a>, has been paraphrased as saying: ‘The ultimate <a id="page_9"></a>goal of mathematics is to eliminate any need for intelligent thought.’ </p>
<p class="TXI">Given this useful feature of mathematics, some scientific subjects – physics chief among them – have developed an ethos centred on rigorous quantitative thinking. Scientists in these fields have capitalised on the power of mathematics for centuries. They know that mathematics is the only language precise and efficient enough to describe the natural world. They know that the specialised notation of equations expertly compresses information, making an equation like a picture: it can be worth a thousand words. They also know that mathematics keeps scientists honest. When communicating through the formalism of mathematics, assumptions are laid bare and ambiguities have nowhere to hide. In this way, equations force clear and coherent thinking. As Bertrand Russell (a colleague of Whitehead whom we will also meet in <a href="chapter3.xhtml#chapter3">Chapter 3</a>) wrote: ‘Everything is vague to a degree you do not realise till you have tried to make it precise.’ </p>
<p class="TXI">The final lesson that quantitative scientists have learnt is that the beauty of mathematics lies in its ability to be both specific and universal. An equation can capture exactly how the pendulum in the barometrical clock on the Ministers’ Landing at Buckingham Palace will swing; the very same equation describes the electrical circuits responsible for broadcasting radio stations around the world. When an analogy exists between underlying mechanisms, equations serve as the embodiment of that analogy. As an invisible thread tying together disparate topics, mathematics is a means by which advances in one field can have surprising and disproportionate impacts on other, far-flung areas.</p><a id="page_10"></a>
<p class="TXI">Biology – including the study of the brain – has been slower to embrace mathematics than some other fields. A certain portion of biologists, for reasons good and bad, have historically eyed mathematics with some scepticism. In their opinion, mathematics is both too complex and too simple to be of much use.</p>
<p class="TXI">Some biologists find mathematics too complex because – trained as they are in the practical work of performing lab experiments and not in the abstract details of mathematical notion – they see lengthy equations as meaningless scribble on the page. Without seeing the function in the symbols, they’d rather do without them. As biologist Yuri Lazebnik wrote in a 2002 plea for more mathematics in his field: ‘In biology, we use several arguments to convince ourselves that problems that require calculus can be solved with arithmetic if one tries hard enough and does another series of experiments.’</p>
<p class="TXI">Yet mathematics is also considered too simple to capture the overwhelming richness of biological phenomena. An old joke among physicists highlights the sometimes absurd level of simplification that mathematical approaches can require. The joke starts with a dairy farmer struggling with milk production. After trying everything he could think to get his beloved cows to produce more, he decides to ask the physicist at the local university for help. The physicist listens carefully to the problem and goes back to his office to think. After some consideration, he comes back to the farmer and says: ‘I found a solution. First, we must assume a spherical cow in a vacuum … ’ </p>
<p class="TXI">Simplifying a problem is what opens it up to mathematical analysis, so inevitably some biological details get lost in <a id="page_11"></a>translation from the real world to the equations. As a result, those who use mathematics are frequently disparaged as being too disinterested in those details. In his 1897 book <span class="italic">Advice for a Young Investigator</span>, Santiago Ramón y Cajal (the father of modern neuroscience whose work is discussed in <a href="chapter9.xhtml#chapter9">Chapter 9</a>) wrote about these reality-avoiding theorists in a chapter entitled ‘Diseases of the Will’. He identified their symptoms as ‘a facility for exposition, a creative and restless imagination, an aversion to the laboratory, and an indomitable dislike for concrete science and seemingly unimportant data’. Cajal also lamented the theorist’s preference for beauty over facts. Biologists study living things that are abundant with specific traits and nuanced exceptions to any rule. Mathematicians – driven by simplicity, elegance and the need to make things manageable – squash that abundance when they put it into equations. </p>
<p class="TXI">Oversimplification and an obsession with aesthetics are legitimate pitfalls to avoid when applying mathematics to the real world. Yet, at the same time, the richness and complexity of biology is exactly why it needs mathematics.</p>
<p class="TXI">Consider a simple biological question. There are two types of animals in a forest: rabbits and foxes. Foxes eat rabbits, rabbits eat grass. If the forest starts off with a certain number of foxes and a certain number of rabbits, what will happen to these two populations? </p>
<p class="TXI">Perhaps the foxes ferociously gobble up the rabbits, bringing them to extinction. But then the foxes, having exhausted their food source, will starve and die off themselves. This leaves us with a rather empty forest. On the other hand, maybe the fox population isn’t so <a id="page_12"></a>ravenous. Perhaps they reduce the rabbit population to almost zero but not quite. The fox population still plummets as each individual struggles to find the remaining rabbits. But then – with most of the foxes gone – the rabbit population can rebound. Of course, now the food for the foxes is abundant again and, if enough of their population remains, they too can resurge.</p>
<p class="TXI">When it comes to knowing the outcome for the forest, there is a clear limitation to relying on intuition. Trying to ‘think through’ this scenario, as simple as it is, using just words and stories is insufficient. To make progress, we must define our terms precisely and state their relationships exactly – and that means we’re doing mathematics. </p>
<p class="TXI">In fact, the mathematical model of predator–prey interactions that can help us here is known as the Lotka–Volterra model and it was developed in the 1920s. The Lotka-Volterra model consists of two equations: one that describes the growth of the prey population in terms of the numbers of prey and predators, and another that describes the growth of the predator population in terms of the numbers of predators and prey. Using dynamical systems theory – a set of mathematical tools initially forged to describe the interactions of celestial bodies – these equations can tell us whether the foxes will eventually die off, or the rabbits will, or if they’ll carry on in this dance together forever. In this way, the use of mathematics makes us better at understanding biology. Without it, we are sadly limited by our own innate cognitive talents. As Lazebnik wrote: ‘Understanding 
[a complex] system without formal analytical tools requires geniuses, who are so rare even outside biology.’</p><a id="page_13"></a>
<p class="TXI">To look at a bit of biology and see how it can be reduced to variables and equations requires creativity, expertise and discernment. The scientist must see through the messy details of the real world and find the bare-bones structure that underlies it. Each component of their model must be defined appropriately and exactly. Once a structure is found and an equation written, however, the fruits of this discipline are manifest. Mathematical models are a way to describe a theory about how a biological system works precisely enough to communicate it to others. If this theory is a good one, the model can also be used to predict the outcomes of future experiments and to synthesise results from the past. And by running these equations on a computer, models provide a ‘virtual laboratory’, a way to quickly and easily plug in different values to see how different scenarios may turn out and even perform ‘experiments’ not yet feasible in the physical world. By working through scenarios and hypotheses digitally this way, models help scientists determine what parts of a system are important to its function and, importantly, which are not. </p>
<p class="TXI">Such integral work could hardly be carried out using simple stories unaccompanied by mathematics. As Larry Abbott, a prominent theoretical neuroscientist and co-author<sup><a href="#fn-1" id="fnt-1">1</a>
</sup> of one of the most widely used textbooks on the subject, explained in a 2008 article:</p>
<p class="EXT">
<span class="italic">Equations force a model to be precise, complete and self-consistent, and they allow its full implications to be worked out. It is not difficult to find word models in the conclusions sections of older <a id="page_14"></a>neuroscience papers that sound reasonable but, when expressed as mathematical models, turn out to be inconsistent and unworkable. Mathematical formulation of a model forces it to be self-consistent and, although self-consistency is not necessarily truth, self-inconsistency is certainly falsehood.</span></p>
<p class="TXT">The brain – composed of (in the case of humans) some 100 billion neurons, each their own bubbling factory of chemicals and electricity, all interacting in a jumble of ways with their neighbours both near and far – is a prime example of a biological object too complex to be understood without mathematics. The brain is the seat of cognition and consciousness. It is responsible for how we feel, how we think, how we move, who we are. It is where days are planned, memories are stored, passions are felt, choices are made, words are read. It is the inspiration for artificial intelligence and the source of mental illness. To understand how all this can be accomplished by a single complex of cells, interfacing with a body and the world, demands mathematical modelling at multiple levels. </p>
<p class="TXI">Despite the hesitancy felt by some biologists, mathematical models can be found hidden in all corners of the history of neuroscience. And while it was traditionally the domain of adventurous physicists or wandering mathematicians, today ‘theoretical’ or ‘computational’ neuroscience is a fully developed subdivision of the neuroscience enterprise with dedicated journals, conferences, textbooks and funding sources. The mathematical mindset is influencing the whole of the study of the brain. As Abbott wrote: ‘Biology used to be a refuge for students fleeing mathematics, but now many <a id="page_15"></a>life sciences students have a solid knowledge of basic mathematics and computer programming, and those that don’t at least feel guilty about it.’<sup><a href="#fn-2" id="fnt-2">2</a>
</sup> </p>
<p class="TXI">Yet the biologist’s apprehension around mathematical models should not be entirely dismissed. ‘All models are wrong,’ starts the popular phrase by statistician George Box. Indeed, all models <span class="italic">are</span> wrong, because all models ignore some details. All models are also wrong because they represent only a biased view of the processes they claim to capture. And all models are wrong because they favour simplicity over absolute accuracy. All models are wrong the same way all poems are wrong; they capture an essence, if not a perfect literal truth. ‘All models are wrong but some are useful,’ says Box. If the farmer in the old joke reminded the physicist that cows are not, in fact, spherical, the physicist’s response would be, ‘Who cares?’, or more accurately, ‘Do we need to care?’. Detail for detail’s sake is not a virtue. A map the size of the city has no good use. The art of mathematical modelling is in deciding which details matter and steadfastly ignoring those that do not. </p>
<p class="TXI">This book charts the influence of mathematical thinking – borrowed from physics, engineering, statistics and computer science – on the study of the brain. Each chapter tells, for a different topic in neuroscience, the story of the biology, the mathematics and the interplay between the two. No special knowledge of mathematics is assumed <a id="page_16"></a>on the part of the reader; the ideas behind the equations will be explained.<sup><a href="#fn-3" id="fnt-3">3</a>
</sup> No single theory of the brain is being proposed; different models solve different problems and offer complementary approaches to understanding. </p>
<p class="TXI">The chapters are ordered from the low to the high level: from the physics of single cells up to the mathematics of behaviour. The stories in these chapters include the struggles encountered in unifying mathematics and biology, and the scientists who did the struggling. They show that sometimes experiments inform models and sometimes models inform experiments. They also show that a model can be anything from a few equations confined to a page to countless lines of code run on supercomputers. In this way, the book is a tapestry of the many forms mathematical models of the brain can take. Yet while the topics and models covered are diverse, common themes do reappear throughout the pages. </p>
<p class="TXI">Of course, everything in this book may be wrong. It may be wrong because it is science and our understanding of the world is ever-evolving. It may be wrong because it is history and there is always more than one way to tell a story. And, most importantly, it <span class="italic">is</span> wrong because it is mathematics. Mathematical models of the mind do not make for perfect replicas of the brain, nor should we strive for them to be. Yet in the study of the most complex object in the known universe, mathematical models are not just useful but absolutely essential. The brain will not be understood though words alone.</p>
<p class="H1">Notes</p>
<p class="FN1"><a href="chapter1.xhtml#fnt-1" id="fn-1">1</a> ﻿Along with Peter Dayan, whom we will meet in ﻿﻿Chapter 11﻿﻿.﻿</p>
<p class="FN1"><a href="chapter1.xhtml#fnt-2" id="fn-2">2</a> ﻿This guilt may not be entirely new. Charles Darwin, certainly a successful biologist, wrote in an 1887 autobiography: ﻿‘﻿I have deeply regretted that I did not proceed far enough at least to understand something of the great leading principles of mathematics, for men thus endowed seem to have an extra sense.﻿’﻿ ﻿</p>
<p class="FN1"><a href="chapter1.xhtml#fnt-3" id="fn-3">3</a> ﻿However, for the mathematically inclined, an appendix elaborating on one of the main equations per chapter is provided at the end of the book. ﻿</p>
</body>
</html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML">
<head>
<title>Chapter 3</title>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000006607108" name="Adept.expected.resource"/>
</head>
<body>
<p class="CN" id="chapter3"><a href="contents.xhtml#re_chapter3">CHAPTER THREE</a></p>
<p class="CT"><a href="contents.xhtml#re_chapter3">Learning to Compute</a><a id="page_49"></a></p>
<p class="H1" id="b-9781472966445-ch222-sec3">
<span class="bold">
<span>McCulloch-Pitts, the Perceptron and 
artificial neural networks</span>
</span></p>
<p class="TXT">Cambridge University mathematician Bertrand Russell spent 10 years at the beginning of the twentieth century toiling towards a monumental goal: to identify the philosophical roots from which all of mathematics stems. Undertaken in collaboration with his former teacher Alfred Whitehead, this ambitious project produced a book, the <span class="italic">Principia Mathematica</span>, which was delivered to the publishers overdue and over budget. The authors themselves had to chip in towards the publishing costs just to get it done and they didn’t see any royalties for 40 years. </p>
<p class="TXI">But the financial hurdle was perhaps the smallest one to overcome in getting this opus finished. Russell had to fight against his own agitation with the scholarly material. According to his autobiography, he spent days staring at a blank sheet of paper and evenings contemplating jumping in front of a train. Work on the book also coincided with the dissolution of Russell’s marriage and a strain on his relationship with Whitehead – who, according to Russell, was fighting his own mental and marital battles at the time. The book was even physically demanding: Russell spent 12 hours a day at a desk writing out the intricate symbolism needed <a id="page_50"></a>to convey his complex mathematical ideas and when the time came to bring the manuscript to the publisher it was too large for him to carry. Despite it all, Russell and Whitehead eventually completed and published the text they hoped would tame the seemingly wild state of mathematics. </p>
<p class="TXI">The conceit of the <span class="italic">Principia</span> was that all of mathematics could be reduced to logic. In other words, Russell and Whitehead believed that a handful of basic statements, known as ‘expressions’, could be combined in just the right way to generate all the formalisms, claims and findings of mathematicians. These expressions didn’t stem from any observations of the real world. Rather, they were meant to be universal. For example, the expression: if X is true, then the statement ‘X is true or Y is true’ is also true. Such expressions are made up of propositions: fundamental units of logic that can be either true or false, written as letters like X or Y. These propositions are strung together with ‘Boolean’ operators<sup><a href="#fn-1" id="fnt-1">1</a>
</sup> such as ‘and’, ‘or’ and ‘not’. </p>
<p class="TXI">In the first volume of the <span class="italic">Principia</span>, Russell and Whitehead provided fewer than two dozen of these abstract expressions. From these humble seeds, they built mathematics. They were even able to triumphantly conclude – after scores of symbol-filled pages – that 1+1=2. </p>
<p class="TXI">Russell and Whitehead’s demonstration that the full grandeur of mathematics could be captured with the simple <a id="page_51"></a>rules of logic<sup><a href="#fn-2" id="fnt-2">2</a>
</sup> had immense philosophical implications as it provided proof of the power of logic. What’s more, it meant that a subsequent finding, made by a different pair of men some 30 years later, would have immense implications of its own. This finding said that neurons, simply via the nature of their anatomy and physiology, were implementing the rules of logic. It revolutionised the study of the brain and of intelligence itself. </p>
<p class="center">* * *</p>
<p class="TXT">When Detroit native Walter Pitts was just 12 years old, he was invited by Russell to join him as a graduate student at Cambridge University. The young boy had, the story goes, encountered a copy of the <span class="italic">Principia</span> after running into a library to avoid bullies. As he read, Pitts found what he believed to be errors in the work. So, he sent his notes on the subject off to Russell, who, presumably not knowing the boy’s age, then offered him the position. Pitts didn’t accept it. But a few years later, when Russell was visiting the University of Chicago, Pitts went to sit in on his lectures. Having fled an abusive family home to come to Chicago, Pitts decided not to return. He remained in the city, homeless. </p>
<p class="TXI">Luckily, the University of Chicago had another world-famous logician for Pitts to criticise – Rudolf Carnap. Again, Pitts wrote up notes – this time identifying issues in Carnap’s recent book <span class="italic">The Logical Syntax of Language</span> – and delivered them to Carnap’s office at the University of Chicago. Pitts didn’t stick around long enough to hear his <a id="page_52"></a>reaction, but Carnap, impressed, eventually chased down Pitts, whom he referred to as ‘that newsboy who understood logic’. On this occasion, the philosopher he critiqued actually did get Pitts to work with him. Though he never officially enrolled, Pitts functioned effectively as a graduate student for Carnap and fraternised with a group of scholars who were interested in the mathematics of biology.</p>
<p class="TXI">Warren McCulloch’s interest in philosophy took a more traditional form. Born in New Jersey, he studied the subject (along with psychology) at Yale and read many of the greats. He was most enamoured with Immanuel Kant and Gottfried Leibniz (whose ideas were very influential for Russell), and he read the <span class="italic">Principia</span> at the age of 25. But, despite the beard upon his long face, McCulloch was not a philosopher – he was a physiologist. He attended medical school in Manhattan and then went on to observe the panoply of ways in which the brain can break as a neurology intern at Bellevue Hospital and at the Rockland State Hospital psychiatric facility. In 1941, he joined the University of Illinois at Chicago as the director of the laboratory for basic research in the department of psychiatry. </p>
<p class="TXI">As with all great origin stories, there are conflicting accounts of how McCulloch and Pitts met. One claims that it happened when McCulloch spoke in front of a research group Pitts was a part of. Another story is that Carnap introduced them. Finally, a contemporary of the two men, Jerome Lettvin, claimed he introduced them and that all three bonded over a mutual love of Leibniz. In any case, by 1942, the 43-year-old McCulloch and his wife had taken the 18-year-old Pitts into their home, <a id="page_53"></a>and the two men were spending evenings drinking whisky and discussing logic. </p>
<p class="TXI">The wall between ‘mind’ and ‘body’ was strong among scientists in the early twentieth century. The mind was considered internal and intangible; the body, including the brain, was physical. Researchers on either side of this wall toiled diligently, but separately, at their own problems. Biologists, as we saw in the last chapter, were working hard to uncover the physical machinery of neurons: using pipettes and electrodes and chemicals to sort out what causes a spike and how. Psychiatrists, on the other hand, were attempting to uncover the machinery of the mind through lengthy sessions of Freudian psychoanalysis. Few on either side would attempt a glance over the wall at the other. They spoke separate languages and worked towards different goals. For most practitioners, the question of how neural building blocks could create the structure of the mind was not just unanswered, it was unasked. </p>
<p class="TXI">But McCulloch, from as early on as his time at medical school, had immersed himself in a crowd of scientists who did care about this question and allowed him the space to think about it. Eventually, through his physiological observations, he came up with a hunch. He saw in the emerging concepts of neuroscience a possible mapping to the notions of logic and computation he so adored in philosophy. To think of the brain as a computing device following the rules of logic – rather than just a bag of proteins and chemicals – would open the door to understanding thought in terms of neural activity.</p> <a id="page_54"></a>
<p class="TXI">Analytical skill, however, was not where McCulloch excelled. Some who knew him say he was too much of a romantic to be held down by such details. So, despite years of toying with these ideas in his mind and in conversation (even as a Bellevue intern he was accused of ‘trying to write an equation for the working of the brain’), McCulloch struggled with several technical issues of how to enact them. Pitts, however, was comparably unfazed by the analytical. As soon as he spoke with him about it, Pitts saw what approaches were needed to formally realise McCulloch’s intuitions. Not long after they met, one of the most influential papers on computation was written.</p>
<p class="TXI">‘A logical calculus of the ideas immanent in nervous activity’ was published in 1943. The paper is 17 pages long with many equations, only three references (one of which is to the <span class="italic">Principia</span>) and a single figure consisting of little neural circuits drawn by McCulloch’s daughter.<sup><a href="#fn-3" id="fnt-3">3</a>
</sup> </p>
<p class="TXI">The paper begins by reviewing the biology of neurons that was known at the time: neurons have cell bodies and axons; two neurons connect when the axon of the first meets the body of the second; through this connection one neuron provides input to the other; a certain amount of input is needed for a neuron to fire; a cell either fires a spike or it doesn’t – no half spikes or in-between spikes; and the input from some neurons – inhibitory neurons – has the power to prevent a cell from spiking.</p><a id="page_55"></a>
<p class="TXI">McCulloch and Pitts go on to explain how these biological details are congruent with Boolean logic. The core of their claim is that the activity state of each neuron – either firing or not – is like the truth value of a proposition – either true or false. In their own words, they ‘conceive of the response of any neuron as factually equivalent to a proposition which proposed its adequate stimulus’. </p>
<p class="TXI">By ‘its adequate stimulus’ they are referring to something about the world. Imagine a neuron in the visual cortex whose activity represents the statement ‘the current visual stimulus looks like a duck’. If that neuron is firing, that statement is true; if the neuron is not firing, it is false. Now imagine another neuron, in the auditory cortex, that represents the statement ‘the current auditory stimulus is quacking like a duck’. Again, if this neuron is firing, that statement is true, otherwise it is false. </p>
<p class="TXI">Now we can use the connections between neurons to enact Boolean operations. For example, by giving a third neuron inputs from both of these neurons, we could implement the rule ‘if it looks like a duck <span class="italic">and</span> it quacks like a duck, it’s a duck’. All we have to do is build the third neuron such that it will only fire if both of its input neurons are firing. That way, both ‘looks like a duck’ and ‘quacks like a duck’ have to be true in order for the conclusion represented by the third neuron (‘it’s a duck’) to be true. </p>
<p class="TXI">This describes the simple circuit needed to implement the Boolean operation ‘and’. McCulloch and Pitts in their paper show how to implement many others. To implement ‘or’ is very similar, however the strength of the connections from each neuron must be so strong <a id="page_56"></a>that one input alone is enough to make the output neuron fire. In this case, the ‘is a duck’ neuron would fire if the ‘looks like a duck’ neuron <span class="italic">or</span> the ‘quacks like a duck’ neuron (or both) were firing. The authors even show how to string together multiple Boolean operations. For example, to implement a statement like ‘X and not Y’, the neuron representing X connects to an output neuron with a strength enough to make it fire. But the neuron representing Y <span class="italic">inhibits</span> the output neuron, meaning it prevents it from firing. This way, the output neuron will only fire if the X-representing neuron <span class="italic">is</span> firing and the Y-representing neuron is <span class="italic">not</span> (see Figure 4). </p>
<p class="TXI">These circuits, which are meant to represent what networks of real neurons can do, became known as <span class="italic">artificial</span> neural networks. </p>
<p class="image-fig" id="fig4.jpg">
<img alt="" src="Images/chapter-01-image-01.jpg"/></p>
<p class="FC">
<span class="bold">
<span class="italic">Figure 4</span>
</span></p>
<p class="TXI">The ability to spot logic at play in the interactions of neurons came from McCulloch’s discerning eye. As a physiologist, he knew that neurons were more complex than his simple drawings and equations suggested. They had membranes, ion channels and forking paths of <a id="page_57"></a>dendrites. But the theory didn’t need their full complexity. So, like an impressionist painter using only the necessary strokes, he intentionally highlighted only the elements of neural activity required for the story he wanted to tell. In doing so, he demonstrated the artistry inherent to model-building; it is a subjective and creative process to decide which facts belong in the foreground. </p>
<p class="TXI">The radical story that McCulloch and Pitts told with their model – that neurons were performing a logical calculus – was the first attempt to use the principles of computation to turn the mind–body problem into a mind–body connection. Networks of neurons were now imbued with all the power of a formal logical system. Like a chain of falling dominoes, once certain truth values entered into a neural population (say, via sensory organs), a cascade of interactions could deduce the truth value of new and different statements. This meant a population of neurons could carry out endless computations: interpreting sensory inputs, developing conclusions, forming plans, reasoning through arguments, performing calculations and so on. </p>
<p class="TXI">With this step in their research, McCulloch and Pitts advanced the study of human thought and, at the same time, kicked it off its throne. The ‘mind’ lost its status as mysterious and ethereal once it was brought down to solid ground – that is, once its grand abilities were reduced to the firing of neurons. To adapt a quote from Lettvin, the brain could now be thought of as ‘a machine, meaty and miraculous, but still a machine’. More boldly still, McCulloch’s student Michael Arbib later remarked that the work ‘killed dualism’.</p><a id="page_58"></a>
<p class="TXI">Russell was known to lament that, despite the 20 years put into it and the impact it had on logicians and philosophers, the <span class="italic">Principia</span> had little effect on practising mathematicians. Its new take on the foundations of mathematics simply didn’t seem to mean much to those doing mathematics; it didn’t change their day-to-day work. The same could be said of McCulloch and Pitts’ discovery for neuroscientists of the time. Biologists, physiologists, anatomists – the scientists doing the labour of physically mining neurons for the details of their workings – didn’t take much from the theory. This was in part because it wasn’t obvious what experiments should follow from it. But it may also have stemmed from the very technical notation in the paper and its less-than-inviting writing style. In a review on nerve conduction written three years later, the author refers to the McCulloch-Pitts paper as ‘not for the lay reader’ and remarks that if this style of work is to be useful, it’s necessary for ‘physiologists to familiarise themselves with mathematical technology, or for mathematicians to elaborate at least their conclusions in a less formidable language’. The wall between mind and body may have come down, but the one between biologist and mathematician stood strong. </p>
<p class="TXI">There was a separate group of people – a group with the requisite technical know-how – who did take an interest in the logical calculus of neurons. In the post-war era, a series of meetings hosted by the philanthropic Macy Foundation brought together biologists and technologists, many of whom wished to use biological findings to build brain-like machines. McCulloch was an organiser of these meetings, and fellow attendees <a id="page_59"></a>included the ‘father of cybernetics’ Norbert Wiener and John von Neumann, the inventor of the modern computer architecture, who was directly inspired in its design by the McCulloch-Pitts neurons. As Lettvin described it 40 years later: ‘The whole field of neurology and neurobiology ignored the structure, the message and the form of McCulloch and Pitts’ theory. Instead, those who were inspired by it were those who were destined to become the aficionados of a new venture, now called Artificial Intelligence.’</p>
<p class="center">* * *</p>
<p class="EXTF">The <span class="italic">Navy last week demonstrated the embryo of an electronic computer named the Perceptron which, when completed in about a year, is expected to be the first non-living mechanism able to 
‘perceive, recognise, and identify its surroundings without human training or control.’ [...]</span> </p>
<p class="EXT-L">
<span class="italic">“‘Dr. Frank Rosenblatt, research psychologist at the Cornell Aeronautical Laboratory, Inc., Buffalo, NY, designer of the ­Perceptron, conducted the demonstration. The machine, he said, would be the first electronic device to think as the human brain. Like humans, Perceptron will make mistakes at first, ‘but it will grow wiser as it gains experience’, he said.</span></p>
<p class="TXT">This summary, from an article entitled ‘Electronic “brain” teaches itself’, appeared in the 13 July 1958 edition of the <span class="italic">New York Times</span>, opposite a letter to the editor about the ongoing debate on whether smoking causes cancer. Frank Rosenblatt, the 30-year-old architect of the project, was reaching beyond his training in experimental psychology to build a computer meant to rival the most advanced technology at the time.</p><a id="page_60"></a>
<p class="TXI">The computer in question was taller than the engineers who operated it and about twice as long. It was covered on either end in various control panels and readout mechanisms. Rosenblatt requested the services of three ‘professional people’ and an associated technical staff for 18 months to build it, and the estimated cost was $100,000 (around $870,000 today). The word ‘perceptron’, defined by Rosenblatt, is a generic term for a certain class of devices that can ‘recognise similarities or identities between patterns of optical, electrical or tonal information’. The Perceptron – the computer that was built in 1958 – was thus technically a subclass known as a ‘photoperceptron’ because it took as its input the output of a camera mounted on a tripod at one end of the machine. </p>
<p class="TXI">The Perceptron was, just like the models introduced in the McCulloch-Pitts paper, an artificial neural network. It was a simplified replica of what real neurons do and how they connect to each other. But rather than remaining a mathematical construct that exists only as the ink of equations on a page, the Perceptron was physically realised. The camera provided 400 inputs to this network in the form of a 20x20 grid of light sensors. Wires then randomly connected the output of these sensors to 1,000 ‘association units’ – small electrical circuits that summed up their inputs and switched to ‘on’ or ‘off’ as a result, just like a neuron. The output of these association units became the input to the ‘response units’, which themselves could be ‘on’ or ‘off’. The number of response units was equal to the number of mutually exclusive categories to which an image could belong. So, if the Navy wanted to use the Perceptron, say, to <a id="page_61"></a>determine if a jet was present in an image or not, there would be two response units: one for jet and one for no jet. At the end of the machine opposite the camera was a set of light bulbs that let the engineer know which of the response units was active – that is, which category the input belonged to. </p>
<p class="TXI">Implementing an artificial neural network this way was large and cumbersome, full of switches, plugboards and gas tubes. The same network made up of real neurons would be smaller than a grain of sea salt. But achieving this physical implementation was important. It meant that theories of how neurons compute could actually be tested in the real world on real data. Whereas the McCulloch-Pitts work was about proving a point in theory, the Perceptron put it into practice. </p>
<p class="TXI">Another important difference between the Perceptron and the McCulloch-Pitts network was that, as Rosenblatt told the <span class="italic">New York Times</span>, the Perceptron learns. In the McCulloch and Pitts paper, the authors make no reference to how the connectivity between the neurons comes to be. It is simply defined according to what logical function the network needs to carry out and it stays that way. For the Perceptron to learn, however, it must modify its connections.<sup><a href="#fn-4" id="fnt-4">4</a>
</sup> In fact, the Perceptron derives all its functionality from changing its connection strengths until they are just right. </p>
<p class="TXI">The type of learning the Perceptron engages in is known as ‘supervised’ learning. By providing pairs of inputs and outputs – say, a series of pictures and whether <a id="page_62"></a>they each contain a jet or not – the Perceptron learns to make this decision on its own. It does so by changing the strength of the connections – also known as the ‘weights’ – between the association units and the readouts. </p>
<p class="TXI">Specifically, when an image is provided to the network, it activates units first in the input layer, then in the association layer, and finally in the readout layer, indicating the network’s decision. If the network gets the classification wrong, the weights change according to these rules:</p>
<p class="NLF">1. If a readout unit is ‘off’ when it should be ‘on’, the connections from the ‘on’ association units to that readout unit are <span class="italic">strengthened</span>.</p>
<p class="NLL">2. If a readout unit is ‘on’ when it should be ‘off’, the connections from the ‘on’ association units to that readout unit are <span class="italic">weakened</span>.</p>
<p class="TXT">By following these rules, the network will start to correctly associate images with the category they belong to. If the network can learn to do this well, it will stop making errors and the weights will stop changing. </p>
<p class="TXI">This procedure for learning was, in many ways, the most remarkable part of the Perceptron. It was the conceptual key that could open all doors. Rather than needing to tell a computer exactly how to solve a problem, you need only show it some examples of that problem solved. This had the potential to revolutionise computing and Rosenblatt was not shy in saying so. He told the <span class="italic">New York Times</span> that Perceptrons would ‘be able to recognise people and call out their names’ and ‘to hear speech in one language and instantly translate it to <a id="page_63"></a>speech or writing in another language’. He also added that ‘it would be possible to build Perceptrons that could reproduce themselves on an assembly line and which would be “conscious” of their existence’. This was a bold statement, to say the least, and not everyone was happy with Rosenblatt’s public bravado. But the spirit of the claim – that a computer that could learn would expedite the solving of almost any problem – rang true.</p>
<p class="TXI">The power of learning, however, came with a price. Letting the system decide its own connectivity effectively divorced these connections from the concept of Boolean operators. The network <span class="italic">could</span> learn the connectivity that McCulloch and Pitts had identified as required for ‘and’, ‘or’, <span class="italic">etc.</span> But there was no requirement that it does, nor any need to understand the system in this light. Furthermore, while the association units in the Perceptron machine were designed to be only ‘on’ or ‘off’, the learning rule doesn’t actually require that they be this way. In fact, the activity level of these artificial neurons could be any positive number and the rule would still work.<sup><a href="#fn-5" id="fnt-5">5</a>
</sup> This makes the system more flexible, but without a binary ‘on’-‘off’ response it makes it harder to map the activity of these units to the binary truth values of propositions. Compared with the crisp and clear logic of the McCulloch-Pitts networks, the Perceptron was an uninterpretable mess. But it worked. Interpretability was sacrificed for ability.</p> <a id="page_64"></a>
<p class="TXI">The Perceptron machine and its associated learning procedure became a popular object of study in the burgeoning field of artificial intelligence. When it made the transition from a specific physical object (the Perceptron) to an abstract mathematical concept (the perceptron algorithm) the separate input and association layers were done away with. Instead, input units representing incoming data connected directly to the readout units and, through learning, these connections changed to make the network better at its task. How and what the perceptron in this simplified form could learn was studied from every angle. Researchers explored its workings mathematically using pen and paper, or physically by building their own perceptron machines, or – when digital computers finally became available – electronically by simulating it.</p>
<p class="TXI">The perceptron generated hope that humans could build machines that learn like we do; in this way it put the prospect of artificial intelligence within 
reach. Simultaneously, it provided a new way of understanding our own intelligence. It showed that artificial neural networks could compute without abiding by the strict rules of logic. If the perceptron could perceive without the use of propositions or operators, it follows that each neuron and connection in the brain needn’t have a clear role in terms of Boolean logic either. Instead, the brain could be working in a sloppier way, wherein, like the perceptron, the function of a network is distributed across its neurons and emerges out of the connections between them. This new approach to the study of the brain became known as ‘connectionism’.</p> <a id="page_65"></a>
<p class="TXI">The work of McCulloch and Pitts was an important stepping stone. As the first demonstration of how networks of neurons could think, it was responsible for getting neuroscience away from the shores of pure biology and into the sea of computation. This fact, rather than the veracity of its claims, is what earns it its place in history. The intellectual ancestor of McCulloch and Pitts’ work, the <span class="italic">Principia Mathematica</span>, could be said to have suffered a similar fate. In 1931, German mathematician Kurt Gödel published ‘On formally undecidable propositions of <span class="italic">Principia Mathematica</span> and related systems’. This paper took the <span class="italic">Principia Mathematica</span> as a starting point to show why its very goal – to explain all of mathematics from simple premises – was impossible to achieve. Russell and Whitehead had not, in fact, done what they believed they did.<sup><a href="#fn-6" id="fnt-6">6</a>
</sup> Gödel’s findings became known as the ‘incompleteness theorem’ and had a revolutionary effect on mathematics and philosophy. An effect that stemmed, in part, from Russell and Whitehead’s failed attempt.</p>
<p class="TXI">Russell and McCulloch were able to take the failings of their respective works in their stride. Pitts, on the other hand, was made of finer cloth. The realisation that the brain was not enacting the beautiful rules of logic tore him apart.<sup><a href="#fn-7" id="fnt-7">7</a>
</sup> This, along with pre-existing mental struggles and the end of a relationship with an important mentor, drove him to drink and experiment with other <a id="page_66"></a>drugs. He became erratic and delirious; he burned his work and withdrew from his friends. He died from the impacts of liver disease in 1969 – the same year McCulloch died. McCulloch was 70; Pitts was 46. </p>
<p class="TXI">* * *</p>
<p class="image-fig" id="fig5.jpg">
<img alt="" src="Images/chapter-01-image-02.jpg"/></p>
<p class="FC">
<span class="bold">
<span class="italic">Figure 5</span>
</span></p>
<p class="TXI">The cerebellum is a forest. Folded up neatly near where the spinal cord enters the skull, this bit of the brain is thick with different types of neurons, like different species of trees, all living in chaotic harmony (see Figure 5). The Purkinje cells are large, easily identified and heavily branched: from the body of these cells, dendrites stretch up and away, like a thousand alien hands raised in prayer. The granule cells are numerous and small – with cell bodies less than half the size of the Purkinje’s – but their reach is far. Their axons initially grow upwards, in parallel with the Purkinje cells’ dendrites. They then make a sharp right turn to run directly through the branches of the Purkinje cells, like power lines through treetops. This is where the granule cells make contact with the Purkinje cells: each Purkinje cell gets input from hundreds of <a id="page_67"></a>thousands of granule cells. Climbing fibres are axons that follow a longer path on their way to the Purkinje cells. These axons come from cells in a different brain region – the inferior olive – from which they navigate all the way to the bottom of the Purkinje cell bodies and creep up around them. Winding their way around the base of the Purkinje cell dendrites like ivy, the climbing fibres form connections. Unlike the granule cells, only a single climbing fibre targets each Purkinje cell. In the cerebellar landscape, Purkinje cells are thus central. They have scores of granule cells imposing on them from the top and a small yet precise set of climbing fibres closing in on them from the bottom. </p>
<p class="TXI">In its twisty, organic way, the circuitry of the cerebellum possesses an organisation and precision unbefitting of biology. It was in this biological wiring that James Albus, a PhD student in electrical engineering working at NASA, saw the principles of the perceptron at play. </p>
<p class="TXI">The cerebellum plays a crucial role in motor control; it helps with balance, coordination, reflexes and more. One of the most widely studied of its abilities is eye-blink conditioning. This is a trained reflex that can be found in everyday life. For example, if a determined parent or roommate tries to get you out of bed in the morning by pulling open the curtains, you’ll instinctively close your eyes in response to the sunlight. After a few days of this, simply the sound of the curtains being opened may be enough to make you blink in anticipation. </p>
<p class="TXI">In the lab, this process is studied in rabbits and the intruding sunlight is replaced by a small puff of air on the eye (just annoying enough to ensure they’ll want to avoid it). After several trials of playing a sound (such as a <a id="page_68"></a>short blip of a pure tone) and following it by this little air puff, the rabbit eventually learns to close its eyes immediately upon hearing the tone. Play the animal a new sound (for example, a clapping noise) that hasn’t been paired with air puffs and it won’t blink. This makes eye-blink conditioning a simple classification task: the rabbit has to decide if a sound it hears is indicative of an upcoming air puff (in which case the eyes should close) or if it is a neutral noise (in which case they can remain open). Disrupt the cerebellum and rabbits can’t learn this task. </p>
<p class="TXI">The Purkinje cells have the power to close the eyes. Specifically, a dip in their normally high firing rate will, via connections the Purkinje cells send out of this area, cause the eyes to shut. Based on this anatomy, Albus saw their place as the readout – that is, they indicate the outcome of the classification. </p>
<p class="TXI">The perceptron learns via supervision: it needs inputs and labels for those inputs to know when it has erred. Albus saw these two functions in the two different types of connections on to Purkinje cells. The granule cells pass along sensory signals; specifically, different granule cells fire depending on which sound is being played. The climbing fibres tell the cerebellum about the air puff; they fire when this annoyance is felt. Importantly, this means the climbing fibres signal an error. They indicate that the animal made a mistake in not closing its eyes when it should have. </p>
<p class="TXI">To prevent this error, the connections from the granule cells to the Purkinje cells need to change. In particular, Albus anticipated that any granule cells that were active before the climbing fibre was active (<span class="italic">i.e.</span>, before an error), <a id="page_69"></a>should weaken their connection to the Purkinje cell. That way, the next time those granule cells fire – <span class="italic">i.e.</span>, the next time the same sound is played – they <span class="italic">won’t</span> cause firing in the Purkinje cells. And that dip in Purkinje cell firing <span class="italic">will</span> cause the eyes to close. Through this changing of connection strengths, the animal learns from its past mistakes and avoids future air puffs to the eye.</p>
<p class="TXI">In this way, the Purkinje cell acts like a president advised by a cabinet of granule cell advisors. At first the Purkinje cell listens to all of them. But if it’s clear that some are providing bad advice – that is, their input is followed by negative news delivered by the climbing fibre – their influence over the Purkinje cell will fade. And the Purkinje cell will act better in the future. It is a process that directly mirrors the perceptron learning rule.</p>
<p class="TXI">When Albus proposed this mapping between the perceptron and the cerebellum in 1971,<sup><a href="#fn-8" id="fnt-8">8</a>
</sup> his prediction about how the connections between granule cells and Purkinje cells should change was just that – a prediction. No one had directly observed this kind of learning in the cerebellum. But by the mid-1980s, evidence had piled up in Albus’ favour. It became clear that the strength of the connection between a granule cell and a Purkinje cell does decrease after an error. The particular molecular mechanisms of this process have even been revealed. We now know that granule cell inputs cause a receptor in <a id="page_70"></a>the membrane of the Purkinje cell to respond, effectively tagging which granule cell inputs were active at a given time. If a climbing fibre input comes later (during an air puff), it causes calcium to flood into the Purkinje cell. The presence of this calcium signals to all the tagged connections to decrease their strength. Patients with fragile X syndrome – a genetic disorder that leads to intellectual disabilities – appear to be missing a protein that regulates this connection from the granule cells on to the Purkinje cell. As a result, they have trouble learning tasks like eye-blink conditioning. </p>
<p class="TXI">The perceptron, with its explicit rules of how learning should proceed in a neural network, offered clear testable ideas for neuroscientists to hunt for – and find – in the brain. In doing so, it was able to connect science across scales. The smallest physical detail – calcium ions moving through the inside of a neuron, for example – inherits a much larger meaning in light of its role in computation. </p>
<p class="center">* * *</p>
<p class="TXT">The reign of the perceptron was cut short in 1969. And with a twist of Shakespearean irony, it was its namesake that killed it. </p>
<p class="TXI">
<span class="italic">Perceptrons</span> was written by Marvin Minsky and Seymour Papert, both mathematicians at the Massachusetts Institute of Technology. The book was subtitled <span class="italic">An Introduction to Computational Geometry</span> and had a simple abstract design on the cover. Minsky and Papert were drawn to write about the topic of perceptrons out of appreciation for Rosenblatt’s invention and a desire to explore it further. <a id="page_71"></a>In fact, Minsky and Papert met at a conference where they were presenting similar results from their explorations into how the perceptron learns. </p>
<p class="TXI">Papert was a native of South Africa with full cheeks, a healthy beard and not one, but <span class="italic">two</span>, PhDs in mathematics. He had a lifelong interest in education and how it could be transformed by computing. Minsky was less than a year older than Papert, with sharper features and large glasses. A New York native, he attended the Bronx High School of Science with Frank Rosenblatt; he was also mentored by McCulloch and Pitts. </p>
<p class="TXI">Minsky and Papert shared with McCulloch and Pitts the compulsive desire to formalise thinking. True advances in understanding computation, they believed, came from mathematical derivations. All the empirical success of the perceptron – whatever computing it was able to carry out or categories it was able to learn – meant next to nothing without a mathematical understanding of why and how it worked. </p>
<p class="TXI">At this time, the perceptron was attracting a lot of attention – and money – from the artificial intelligence community. But it wasn’t attracting the kind of mathematical scrutiny Minsky and Papert yearned for. The two were thus explicitly motivated to write their book by a desire to increase the rigour around the study of perceptrons – but also, as Papert later acknowledged, by some desire to decrease the reverence for them.<sup><a href="#fn-9" id="fnt-9">9</a>
</sup></p>
<p class="TXI">The pages of <span class="italic">Perceptrons</span> are comprised mainly of proofs, theorems and derivations. Each contributes to a <a id="page_72"></a>story about the perceptron: defining what it is, what it can do and how it learns. Yet from the publication of these some 200 pages – a thorough exploration of the ins and outs of the perceptron’s workings – the message the community received was largely about its limitations. This is because Minsky and Papert had shown, conclusively, that certain simple computations were impossible for the perceptron to do. </p>
<p class="TXI">Consider a perceptron that has just two inputs, and each input can be ‘on’ or ‘off’. We want the perceptron to report if the two inputs are the same: to respond yes (<span class="italic">i.e.</span>, have its readout unit be on) if both inputs are on <span class="italic">or</span> if both inputs are off. But if one is on and the other is off, the readout unit should be off. Like sorting socks out of the laundry, the perceptron should only respond when it sees a matching pair.</p>
<p class="TXI">To make sure the readout doesn’t fire when only one input is on, the weights from each input need to be sufficiently low. They could, for example, each be half the amount needed to make the readout turn on. This way, when both are on, the readout <span class="italic">will</span> fire and it won’t fire when only one input is on. In this setup the readout is responding correctly for three of the four possible input conditions. But in the condition where both inputs are off, the readout will be off – an incorrect classification. </p>
<p class="TXI">As it turns out, no matter how much we fiddle with connection strengths, there is no way to satisfy all the needs of the classification at once. The perceptron simply cannot do it. And the problem with that is that no good model of the brain – or promising artificial intelligence – should fail at a task as simple as deciding if two things are the same or not.</p> <a id="page_73"></a>
<p class="TXI">Albus, whose paper on the cerebellum was published in 1971, knew of the limitations of the perceptron and knew that, despite these limitations, it was still powerful enough to be a model of the eye-blink conditioning task. But a model of the whole human brain, as Rosenblatt promised? Not possible.</p>
<p class="TXI">The portrait that Minsky and Papert painted forced researchers to see the perceptron’s powers clearly. Prior to the book, researchers were able to explore what the perceptron could do blindly, with the hope that the limits of its abilities were still far off, if they existed at all. Once the contours were put in stark relief, however, there was no denying that these boundaries existed, and that they existed much closer than expected. In truth, all this amounted to was an understanding of the perceptron – exactly what Minsky and Papert set out to do. But the end of ignorance around the perceptron meant the end of excitement around it as well. As Papert put it: ‘Being understood can be a fate as bad as death.’</p>
<p class="TXI">The period that followed the publication of <span class="italic">Perceptrons</span> is known as the ‘dark ages’ of connectionism. It was marked by significant decreases in funding to the research programmes that had grown out of Rosenblatt’s initial work. The neural network approach to building artificial intelligence was snuffed out. All the excessive promises, hopes and hype had to be retracted. Rosenblatt himself died tragically in a boating accident two years after the book was published and the field he helped build remained dormant for more than 10 years.</p>
<p class="TXI">But if the hype around the perceptron was excessive and ill informed, so too was the backlash against it. The limitations in Minsky and Papert’s book were true: the <a id="page_74"></a>perceptron in the form they were studying it was incapable of many things. But it didn’t need to keep that form. The same-or-not problem, for example, could be easily solved by adding an additional layer of neurons between the input and the readout. This layer could be composed of two neurons, one with weights that make it fire when both inputs are on and the other with weights that make it fire when both inputs are off. Now the readout neuron, which gets its input from these middle neurons, just needs to be active if one of the middle neurons is active. </p>
<p class="TXI">‘Multi-layer perceptrons’, as these new neural architectures were called, had the potential to bring connectionism back from the dead.<sup><a href="#fn-10" id="fnt-10">10</a>
</sup> But before a full resurrection was possible, one problem had to be solved: learning. The original perceptron algorithm provided the recipe for setting the connections between the input neurons and the readout neurons – that is, the learning rule was designed for a two-layered network. If the new breed of neural networks was going to have three, four, five or more layers, how should the connections between all those layers be set? (see Figure 6) Despite all the good features of the perceptron learning rule – its simplicity, the proof that it could work, the fact that it had been spotted in the wild of the cerebellum – it was unable to answer this question. Knowing that a multi-layer perceptron <span class="italic">could</span> solve more complex problems was not enough to deliver <a id="page_75"></a>on the grand promises of connectionism. What was needed was for it to <span class="italic">learn</span> to solve those problems.</p>
<p class="center">* * *</p>
<p class="TXT">The Easter Sunday of the connectionist revival story came in 1986. The paper ‘Learning representations by back-propagating errors’, written by two cognitive scientists from the University of California San Diego, David Rumelhart and Ronald Williams, and a computer scientist from Carnegie Mellon, Geoffrey Hinton, was published on 9 October in the journal <span class="italic">Nature</span>. It presented a solution to the exact problem the field had: how to train multi-layer artificial neural networks. The learning algorithm in the paper, called ‘backpropagation’, became widely used by the community at the time. And it remains to this day the dominant way in which artificial neural networks are trained to do interesting tasks.</p>
<p class="image-fig" id="fig6.jpg">
<img alt="" src="Images/chapter-01-image-03.jpg"/></p>
<p class="FC">
<span class="bold">
<span class="italic">Figure 6</span>
</span></p>
<p class="TXI">The original perceptron’s learning rule works because, with only two layers, it’s easy to see how to fix what’s gone wrong. If a readout neuron is off when it should be on, connections going from the input layer to that neuron <a id="page_76"></a>need to get stronger and vice versa. The relationship between these connections and the readout is thus clear. The backpropagation algorithm has a more difficult problem to solve. In a network with many layers between the input and readout, the relationships between all these connections and the readout aren’t as clear. Now instead of a president and his or her advisors, we have a president, their advisors, and the employees of those advisors. The amount of trust an advisor has in any given employee – <span class="italic">i.e.</span>, the strength of the connection from that employee to the advisor – will certainly have an impact, ultimately, on what the president does. But this impact is harder to directly see and harder to fix if the president feels something is going wrong. </p>
<p class="TXI">What was needed was an explicit way to calculate how any connection in the network would impact the readout layer. As it turns out, mathematics offers a neat way to do this. Consider an artificial neural network with three layers: input, middle and readout. How do the connections from the input to the middle layer impact the readout? We know the activity of the middle layer is a result of the activities of the input neurons and the weights of their connections to the middle layer. With this knowledge, writing an equation for how these weights affect the activity at the middle layer is straightforward. We also know that the readout neurons follow the same rule: their activity is determined by the activities of the middle neurons and the weights connecting the middle neurons to the readout. Therefore, an equation describing how these weights impact the readout is also easy to get. The only thing left to do is find a way to string these two equations together. That <a id="page_77"></a>way we’ll have an equation that tells us directly how the connections from the input to the middle layer impact the readout. </p>
<p class="TXI">When forming a train in the game of dominoes, the number on the end of one tile needs to match the number on the start of another in order for them to connect. The same is true for stitching together these equations. Here, the common term that connects the two equations is the activity of the middle layer: this activity both determines the activity of the readout and is determined by the input-to-middle connections. After joining these equations via the middle layer activity, the impact of the input-to-middle layer connections on the readout can be calculated directly. And this makes it easy to figure out how those connections should change when the readout is wrong. In calculus, this linking together of relationships is known as the ‘chain rule’ and it is the core of the backpropagation algorithm. </p>
<p class="TXI">The chain rule was discovered over 200 years ago by none other than the idol of McCulloch and Pitts, philosopher and polymath Gottfried Leibniz. Given how useful the rule is, its application to the training of multi-layer neural networks was no surprise. In fact, the backpropagation algorithm appears to have been invented at least three separate times before 1986. But the 1986 paper was part of a perfect storm that ensured its findings would spread far and wide. The first reason for this was the content of the paper itself. Not only did it show that neural networks could be trained this way, it also analysed the workings of networks trained on several cognitive tasks, such as understanding relations on a family tree. Another component of the success was the <a id="page_78"></a>increase in computational power that came in the 1980s; this was important for making the training of multi-layer neural networks practically possible for researchers. Finally, the same year the paper was published, one of its authors, Rumelhart, also published a book on connectionism that included the backpropagation algorithm. That book – written with a different Carnegie Mellon professor, James McClelland – went on to sell an estimated 40,000 copies by the mid-1990s. Its title, <span class="italic">Parallel Distributed Processing</span>, lent its name to the entire research agenda of building artificial neural networks in the late 1980s and early 1990s. </p>
<p class="TXI">For somewhat similar reasons, the story of artificial neural networks took an even more dramatic turn roughly a decade into the new millennium. The heaps of data accumulated in the internet age united with the computational power of the twenty-first century to supercharge progress in this field. Networks with more and more layers could suddenly be trained on more and more complex tasks. Such scaled-up models – referred to as ‘deep neural networks’ – are currently transforming artificial intelligence and neuroscience alike. </p>
<p class="TXI">The deep neural networks of today are based on the same basic understanding of neurons as those of McCulloch and Pitts. Beyond that base inspiration, though, they don’t aim to directly replicate the human brain. They aren’t trying to mimic its structure or anatomy, for example.<sup><a href="#fn-11" id="fnt-11">11</a>
</sup> But they do aim to mimic human behaviour and they’re getting quite good at it. When <a id="page_79"></a>Google’s popular language translation service started using a deep neural network approach in 2016, it reduced translation errors by 50 per cent. YouTube also uses deep neural networks to help its recommendation algorithm better understand what videos people want to see. And when Apple’s voice assistant Siri responds to a command, it is a deep neural network that is doing the listening and the speaking. </p>
<p class="TXI">In total, deep neural networks can now be trained to find objects in images, play games, understand preferences, translate between different languages, turn speech into written words and turn written words into speech. Not unlike the original Perceptron machine, the computers these networks run on fill up rooms. They’re located in server centres across the globe, where they hum away processing the world’s image, text and audio data. Rosenblatt may have been pleased to see that some of his grand promises to the <span class="italic">New York Times</span> were indeed fulfilled. They just required a scale nearly a thousand times what he had available at the time. </p>
<p class="TXI">The backpropagation algorithm was necessary to boost artificial neural networks to the point where they could reach near-human levels of performance on some tasks. As a learning rule for neural networks, it really works. Unfortunately, that doesn’t mean it works like the brain. While the perceptron learning rule was something that could be seen at play between real neurons, the backpropagation algorithm is not. It was designed as a mathematical tool to make artificial neural networks work, not a model of how the brain learns (and its inventors were very clear on that from the start). The reason for this is that real neurons can typically only <a id="page_80"></a>know about the activity of the neurons they’re connected to – not about the activity of the neurons those neurons connect to and so on and so on. For this reason, there is no obvious way for real neurons to implement the chain rule. They must be doing something different. </p>
<p class="TXI">For some researchers – particularly researchers in the field of artificial intelligence – the artificial nature of backpropagation is no problem. Their goal is to build computers that can think, by whatever means necessary. But for other scientists – neuroscientists in particular – finding the learning algorithm of the brain is paramount. We know the brain is good at getting better; we see it when we learn a musical instrument, how to drive or how to read a new language. The question is how.</p>
<p class="TXI">Because backpropagation is what we know works, some neuroscientists are starting there. They’re checking for signs that the brain is doing something <span class="italic">like</span> backpropagation, even if it can’t do it exactly. Inspiration comes from the success story of finding a perceptron at work in the cerebellum. There, clues were present in the anatomy; the different placement of the climbing fibres and granule cells pointed to a different role for each. Other brain areas display patterns of connectivity which may hint at how they are learning. For example, in the neocortex, some neurons have dendrites that stretch out way above them. Faraway regions of the brain send inputs to these dendrites. Do they carry with them information about how these neurons have impacted those that come after them in the brain’s neural network? Could this information be used to change the strength of the network’s connections? Both neuroscientists and artificial intelligence researchers hold out hope that the <a id="page_81"></a>brain’s version of backpropagation will be found and that, when it is, it can be copied to create algorithms that learn even better and faster than today’s artificial neural networks. </p>
<p class="TXI">In their hunt to understand how the mind learns from supervision, modern researchers are doing just what McCulloch did. They’re looking at the piles of facts we have about the biology of the brain and trying to see in it a computational structure. Today, they are guided in their search by the workings of artificial systems. Tomorrow, the findings from biology will again guide the building of artificial intelligence. This back-and-forth defines the symbiotic relationship between these two fields. Researchers looking to build artificial neural networks can take inspiration from the patterns found in biological ones, while neuroscientists can look to the study of artificial intelligence to identify the computational role of biological details. In this way, artificial neural networks keep the study of the mind and the brain connected.</p>
<p class="H1">Notes</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-1" id="fn-1">1</a> ﻿Named after the English mathematician George Boole. While they used his ideas, Russell and Whitehead didn﻿’﻿t actually use the term ﻿‘﻿Boolean﻿’﻿, as it wasn﻿’﻿t coined until 1913.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-2" id="fn-2">2</a> ﻿At least that﻿’﻿s what it looked like at the time ﻿…﻿ More on this later.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-3" id="fn-3">3</a> ﻿The use of the word ﻿‘﻿circuit﻿’﻿ here differs from that in the last chapter. In addition to its meaning as an electrical circuit, neuroscientists also use the word to refer to a group of neurons connected in a specific way. ﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-4" id="fn-4">4</a> ﻿More on how learning ﻿–﻿ and memory ﻿–﻿ relies on a change in connections in the next chapter.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-5" id="fn-5">5</a> ﻿This can be thought of as representing the ﻿<span class="italic">rate</span>﻿ of spiking of a neuron, rather than if the neuron is emitting a spike or not. Using this type of artificial neuron only requires a small modification to the learning procedure.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-6" id="fn-6">6</a> ﻿The cracks in the ﻿<span class="italic">Principia</span>﻿﻿’﻿s foundation were noticeable even when it was published. Some of the ﻿‘﻿basic﻿’﻿ premises it had to assume were not really very basic and were hard to justify.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-7" id="fn-7">7</a> ﻿This realisation came even more directly from a study on the frog brain that Pitts was involved with. More on that study in ﻿﻿Chapter 6﻿﻿.﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-8" id="fn-8">8</a> ﻿The mapping is sometimes referred to as the ﻿‘﻿Marr-Albus-Ito﻿’﻿ theory of motor learning, named also after David Marr and Masao Ito, who both put forth similar models of how the cerebellum learns. ﻿</p>
<p class="FN1"><a href="chapter3.xhtml#fnt-9" id="fn-9">9</a> ﻿The particular words Papert used to describe his feelings about Perceptron-mania at the time were ﻿‘﻿hostility﻿’﻿ and ﻿‘﻿annoyance﻿’﻿.﻿</p>
<p class="FN2"><a href="chapter3.xhtml#fnt-10" id="fn-10">10</a> ﻿Technically they weren﻿’﻿t ﻿‘﻿new﻿’﻿. Minsky and Papert do reference multi-layer perceptrons in their book. However, they were dismissive about the potential powers of these devices and, unfortunately for science, did not encourage their further study. ﻿</p>
<p class="FN2"><a href="chapter3.xhtml#fnt-11" id="fn-11">11</a> ﻿With the exception of deep neural networks that are built to understand images, which we will hear all about in ﻿﻿Chapter 6﻿﻿.﻿</p>
</body>
</html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML">
<head>
<title>Chapter 9</title>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000006607108" name="Adept.expected.resource"/>
</head>
<body>
<p class="CN" id="chapter9"><a href="contents.xhtml#re_chapter9">CHAPTER NINE</a></p>
<p class="CT"><a href="contents.xhtml#re_chapter9">From Structure to Function</a><a id="page_247"></a></p>
<p class="H1" id="b-9781472966445-ch968-sec10">
<span class="bold">
<span>Graph theory and network neuroscience</span>
</span></p>
<p class="TXT">In 1931, three years before his death, Santiago Ramón y Cajal gave the Cajal Institute in Madrid a trove of his personal possessions. The collection contained all manner of scientific trinkets: balances, slides, cameras, letters, books, microscopes, solutions, reagents. But the items most notable – the ones that would become nearly synonymous with the name Cajal – were the 1,907 scientific drawings he had created throughout his career.</p>
<p class="TXI">Most of these drawings were of different parts of the nervous system and were produced via a laborious cell-staining process. It started with a live animal, which was sacrificed and its tissues preserved. A chunk of the brain was then removed and soaked in a solution for two days, dried and soaked in a different solution – this one containing silver that would penetrate the cell structures – for another two days. At the end of this, the brain tissue was rinsed, dried again and cut into slices thin enough to fit on a microscope slide. Cajal looked at these slides through the eyepiece of his microscope and sketched what he saw. Starting first with pencil, he outlined every nook and cranny of each neuron’s shape on a piece of cardboard, including the thick cell bodies and the thin appendages that emerged from them. He then darkened in the cells with India ink, occasionally using watercolours <a id="page_248"></a>to add texture and dimension. The result was a set of haunting silhouettes of stark, black spider-like figures against beige and yellow backgrounds.<sup><a href="#fn-1" id="fnt-1">1</a>
</sup> The exact contours and configurations depended on the animal and the nerve fibres in question; more than 50 different species and nearly 20 different parts of the nervous system are portrayed on Cajal’s cardboard canvases.</p>
<p class="TXI">These hundreds of portraits represent the infatuation Cajal had with the <span class="italic">structure</span> of the nervous system. He sought enlightenment in the basic unit of the brain – the neuron. He fixated on how they were shaped and how they were arranged. A focus on its physical foundations was Cajal’s inroad to understanding how the brain worked. Function, he believed, could be found in structure. </p>
<p class="TXI">And he was right. Cajal was able to deduce important facts about the workings of the brain by looking long and hard at how it was built. One of his significant findings was about how signals flow through neurons. Through his many observations of different neurons in different sensory organs, Cajal noticed that the cells were always arranged a certain way. The many branched dendrites of a cell would face the direction the signal was coming from. The long singular axon, on the other hand, went towards the brain. In the olfactory system, for example, neurons with the chemical receptors capable of picking up odour molecules exist in the mucousy skin <a id="page_249"></a>inside the nose. These neurons send their axons up into the brain and make contact with the dendrites of cells in the olfactory bulb. These neurons then have axons that go further on into other parts of the brain. </p>
<p class="TXI">This pattern – which Cajal saw over and over – strongly suggested that signals flow from dendrites through to axons. Dendrites, he concluded, act as the receiver of signals for a cell and axons the sender of signals on to the next cell. So clear was Cajal on this that he added little arrows to his drawings of circuits like the olfactory system, indicating the presumed direction of information flow. Cajal, as we now know, was exactly correct. </p>
<p class="TXI">Cajal was one of the founding fathers of modern neuroscience. As such, his belief in the relationship between structure and function was entered into the DNA of the field. Reflections of this idea are peppered throughout neuroscience’s history. In a 1989 article, Peter Getting wrote that researchers in the 1960s could see, even through their limited data, that ‘the abilities of a network arose from the interconnection of simple elements into complex networks, thus, from connectivity emerged function’. Studies in the 1970s, he goes on to say, ‘were approached with several expectations in mind: first, a knowledge of the connectivity would explain how neural networks operated’. This attitude persists. A review written in 2016 by professors Xiao-Jing Wang and Henry Kennedy ends with the statement: ‘Establishing a firm link from structure to function is essential to understand complex neural dynamics.’</p>
<p class="TXI">Structure exists at many scales in the brain. Neuroscientists can look at the shape of a neuron, as <a id="page_250"></a>Cajal did. Or they can look at how neurons are wired up: does neuron A connect to neuron B? They can zoom out even further and ask how small populations of neurons interact. Or they can investigate brain-wide connectivity patterns by looking at the thick bundles of axons that connect distant brain regions. Any of these higher-level structures may hold secrets about function as well. </p>
<p class="TXI">But to unearth these secrets, neuroscientists need a way to see and study these structures clearly. Something that could’ve been considered a limitation of the staining method Cajal used – that it stained only a small number of neurons at a time – was actually an advantage that made it revolutionary. A method that stained all neurons in the field of view would’ve produced a black mess with no discernible structures; it would’ve missed the trees for the forest. Since neuroscientists have moved their study of structure away from single neurons and on to the more complicated subject of connections, networks and circuits, they may be at even higher risk of being overwhelmed by data and distracted by the wrong details. </p>
<p class="TXI">A much-needed method, however, has been found in a particular subfield of mathematics: graph theory. The language of graph theory offers a way to talk about neural networks that cuts away much of the detail. At the same time, its tools find features of neural structure that are near impossible to see without it. These features of the structure, some scientists now believe, can inspire new thoughts on the function of the nervous system. Swept up by the promise of graph theory’s methods, neuroscientists are currently applying it to everything <a id="page_251"></a>from brain development to disease. Though the dust has not yet settled on this new approach to the brain, its fresh take on old problems is exciting many. </p>
<p class="center">* * *</p>
<p class="TXT">In the eighteenth-century East Prussian capital of Königsberg, a river branched in two as it cut through the town, creating a small island in the middle. Connecting this island with parts of the town north, south and east of it were seven bridges. At some point a question arose among the citizens of Königsberg: is there a way to navigate through the city that crosses each of the bridges once and only once? When this playful question met the famous mathematician Leonhard Euler, the field of graph theory was born.</p>
<p class="TXI">Euler, a polymath who was born in Switzerland but lived in Russia, wrote ‘<span class="italic">Solutio problematis ad geometriam situs pertinentis</span>’ or ‘The solution of a problem relating to the geometry of position’ in 1736. In the paper, he answered the question definitively: a Königsberger could <span class="italic">not</span> take a walk through their town crossing each bridge exactly once. To prove this he had to simplify the town map into a skeleton of its full structure and work logically with it. He had shown, without using the word, how to turn data into a <span class="italic">graph</span> and how to perform computations on it (see Figure 20).</p>
<p class="TXI">Within the context of graph theory, the word ‘graph’ does not refer to a chart or a plot, as it does in common language. Rather, a graph is a mathematical object, composed of <span class="italic">nodes</span> and <span class="italic">edges</span> (in the modern parlance). Nodes are the base units of the graph and edges represent <a id="page_252"></a>the connections between them. In the Königsberg example, the bridges serve as edges that connect the four different land masses, the nodes. The degree of a node is the number of edges it has; the ‘degree’ of a land mass is thus the number of bridges that reach it.</p>
<p class="image-fig" id="fig20.jpg">
<img alt="" src="Images/chapter-01-image-04.jpg"/></p>
<p class="FC">
<span class="bold">
<span class="italic">Figure 20</span>
</span></p>
<p class="TXI">Euler approached the bridge-crossing question by first noting that a path through town could be written down as a list of nodes. Giving each land mass a letter name, the list ‘ABDC’, for example, would represent a path that goes from the island at the centre to the land at the bottom (via any bridge that connects them), then from there to the land mass on the right and then on to the land at the top. In such a path through a graph, one edge is traversed between each pair of nodes. Therefore, the number of bridges crossed is equal to the number of letters in the list minus one. For example, if you’ve crossed two bridges, you’d have three land masses on your list. </p>
<p class="TXI">Euler then noticed something important about the number of bridges that each land mass has. This number is related to how many times the land mass should show <a id="page_253"></a>up in the path list. For example, land mass B has three bridges, which means ‘B’ must appear twice in any path that crosses each bridge once – that is, there is no way to cross these three bridges without visiting B twice. The same is true for land masses C and D, as they both have two bridges too. And land mass A, with five bridges, needs to appear three times in the path list. </p>
<p class="TXI">Taken together, any path that satisfies these require­ments would be nine (2+2+2+3) letters long. A list of nine letters, however, represents a path that crosses <span class="italic">eight</span> bridges. Therefore, it is impossible to build a path that crosses each of the seven bridges only once. </p>
<p class="TXI">Using this relationship between a node’s degree and the number of times the node should appear in a path, Euler derived a set of general rules about what paths were possible. He could now say for <span class="italic">any</span> set of bridges connecting <span class="italic">any</span> patches of land whether a path crossing each bridge only once existed. </p>
<p class="TXI">More than that, it doesn’t matter if we are talking about land and bridges at all. The same procedure could be used to find paths for a town snowplough that needs to clear each street only once or to see if it’s possible to traverse Wikipedia clicking each hyperlink between sites just one time. This pliability is part of what gives graph theory its potency. By stripping away the details of any specific situation, it finds the structure that is similar to them all. This abstract and alien way of looking at a problem can open it up to new and innovative solutions, just as treating a walk through town as a list of letters helped Euler. </p>
<p class="TXI">Given this feature, graph theory found purpose in many fields. Chemists in the nineteenth century wrestled <a id="page_254"></a>for some time with how to represent the structure of molecules. By the 1860s, a system was developed that is still in use today: atoms are drawn as letters and the bonds between them as lines. In 1877, English mathematician James Joseph Sylvester saw in this graphical representation of molecules a parallel to the work being done by descendants of Euler in mathematics. He published a paper drawing out the analogy and used, for the first time, the word ‘graph’ to refer to this form. Since then, graph theory has helped solve many problems in chemistry. One of its most common applications is finding isomers – sets of molecules that are each made up of the same type and number of atoms, but differ in how those atoms are arranged. Because graph theory provides a formal language for describing the structure of atoms in a molecule, it is also well suited for enumerating all the structures that are possible given a particular set of atoms. Algorithms that do this can aid in the design of drugs and other desirable compounds. </p>
<p class="TXI">Like a chemical compound, the structure of the brain lends itself well to a graph. In the most basic mapping, neurons are the nodes and the connections between them are the edges. Alternatively, the nodes can be brain areas and the nerve tracts that connect them the edges. Whether working on the microscale of neurons or the macroscale of brain regions, putting the brain into the terms of graph theory exposes it to all the tools of analysis this field has developed. It is a way of formalising the informal quest that has always guided neuroscience. To speak of how structure births function first requires the ability to speak clearly about structure. Graph theory provides the language.</p><a id="page_255"></a>
<p class="TXI">Of course, there are differences between the brain and a Prussian town or a chemical compound. The connections in the brain aren’t always a two-way street like they are on a bridge or in a bond. One neuron can connect to another without it receiving a connection back. This unidirectional nature of neural connections is important for the way information flows through neural circuits. The most basic graph structures don’t capture this, but by the late 1800s, the concept of <span class="italic">directed</span> graphs had been added to the arsenal of mathematical descriptors. In a directed graph, edges are arrows that only flow one way. The degree of a node in a directed graph is thus broken down into two categories: the in-degree (for example, how many connections a neuron receives) and the out-degree (how many connections it sends out to other neurons). A study done on neurons in the cortex of monkeys found these two types of degree to be roughly equal, meaning neurons give as much as they receive. </p>
<p class="TXI">In 2018, mathematicians Katherine Morrison and Carina Curto built a model of a neural circuit with directed edges in order to answer a question not so dissimilar to the Königsberg bridge problem. Rather than determining what walks through town a certain set of bridges can support, they explored what sequence of neural firing a given circuit could produce. By bringing in tools from graph theory, Morrison and Curto figured out how to look at a structure of up to five model neurons and predict the order in which they will fire. Ordered patterns of neuronal firing are important for many of the brain’s functions, including memory and navigation. This five-neuron model may only be a toy <a id="page_256"></a>example, but it perfectly encapsulates the power promised by bringing graph theory into the study of the brain. </p>
<p class="TXI">For real brain networks, however, a more ‘global’ perspective needs to be taken.</p>
<p class="center">* * *</p>
<p class="TXT">Over the course of a few months in the late 1960s, a stockbroker living in Sharon, Massachusetts, was given 16 brown folders from the proprietor of a local clothing store. Strange though this was, the folders weren’t a surprise to the stockbroker. They were simply part of an unorthodox social experiment being run by the famous social psychologist Stanley Milgram. With this experiment, Milgram wanted to test just how big – or small – the world truly was. </p>
<p class="TXI">The phrase ‘it’s a small world’ is usually uttered when two strangers meet and serendipitously discover that they have a friend or relative in common. Milgram wanted to know just how often something like this could happen: what are the odds that two people chosen at random have a friend in common? Or a friend of a friend? Framed another way, if we could see the entire network of human connections – a graph where each node is a person and each edge a relationship – what would the average distance between people be? How many edges would we need to traverse to find a path between any two nodes?</p>
<p class="TXI">In a bold attempt to answer this question, Milgram chose a target person (in this case, the Massachusetts stockbroker) and several starters: unrelated people in another part of the country (in this case, mostly Omaha, <a id="page_257"></a>Nebraska). The starters were given a package with a folder and information about the target person. The instructions were simple: if you know the target, give the folder to them; otherwise, send it on to a friend of yours who you think has a better shot of knowing them. The next person would be told to follow the same instructions and, hopefully, eventually the folder would end up with the target. The senders were also asked to write their name in a register that was sent along with the package, so that Milgram could trace the path the folder took. </p>
<p class="TXI">Looking at a total of 44 folders that made it back to the stockbroker, Milgram found that the shortest path consisted of just two intermediate people and the longest had 10. The median was just five. Getting the folder through five people between the starter and the target involved six handoffs and thus the notion of ‘six degrees of separation’ – already posited by observant scientists and sociologists – was solidified.<sup><a href="#fn-2" id="fnt-2">2</a>
</sup> </p>
<p class="TXI">This concept percolated through the popular imagination. One day, in the late 1990s, graduate student Duncan Watts was asked by his father if he realised that he was only six handshakes away from the president. Watts, working for mathematician Steven Strogatz at the time, brought up this idea as they were discussing how groups of crickets could communicate. After this chance conversation, ‘small world’ would go from a quaint <a id="page_258"></a>expression to a mathematically defined property of a network.</p>
<p class="TXI">In 1998, Watts and Strogatz published a paper laying out just what it takes for a graph to function like a small world. The notion of a short average path length – the idea that any two nodes are separated by only a few steps – was a key component of it. One way to get short path lengths is to make the graph heavily interconnected, <span class="italic">i.e.</span> a graph where each node connects directly to many others. This trick, however, is in clear violation of what we know about social networks: the average citizen of America – a country of around 200 million at the time – had only about 500 acquaintances, according to Milgram. </p>
<p class="TXI">So, Watts and Strogatz limited their network simulations to those with sparse connections, but varied exactly what those connections looked like. They noticed that it was possible to have short path lengths in a network that was highly <span class="italic">clustered</span>. A cluster refers to a subset of nodes that are heavily interconnected, like the members of a family. In these networks, most nodes form edges just with other nodes in their cluster, but occasionally a connection is sent to a node in a distant cluster. The same way a train between two cities makes interactions between their citizens easier, these connections between different clusters in a network keeps the average path length low. </p>
<p class="TXI">Once these characteristics were identified in their models, Watts and Strogatz went looking for them in real data – and found them. The power grid system of the United States – turned into a graph by considering any generator or substation as a node and transmission lines as edges – has the low path length and high clustering of <a id="page_259"></a>a small world network. A graph made of actors with edges between any pairs that have starred in a movie together is the same. And the final place that they looked for, and found, a small world network was in the brain. </p>
<p class="TXI">More specifically, the structure Watts and Strogatz analysed was the nervous system of the tiny roundworm, <span class="italic">Caenorhabditis elegans</span>. Ignoring the directionality of the neural connections, Watts and Strogatz treated any connection as an edge and each of the 282 neurons in the worm’s wiring diagram as a node. They found that any two neurons could be connected by a path with, on average, only 2.65 neurons in between them and that the network contained far more clustering than would be expected if those 282 neurons were wired up randomly. </p>
<p class="TXI">Why should the nervous system of a nematode have the same shape as the social network of humans? The biggest reason may be energy costs. Neurons are hungry. They require a lot of energy to stay in working order and adding more or longer axons and dendrites only ups the bill. A fully interconnected brain is, thus, a prohibitively expensive brain. Yet if connections become too sparse the very function of the brain – processing and routing information – breaks down. A balance must be struck between the cost of wiring and the benefit of information sharing. Small worlds do just this. In a small world, the more common connections are the relatively cheap ones between cells in a local cluster. The pricey connections between faraway neurons are rare, but there are enough to keep information flowing. Evolution, it seems, has found small worldness to be the smart solution. </p>
<p class="TXI">Watts and Strogatz’s finding in the roundworm was the first time the nervous system was described in the <a id="page_260"></a>language of graph theory. Putting it into these terms made visible some of the constraints that are shared by the brain and other naturally occurring networks. Connections can be expensive to maintain, be they acquaintanceships or axons, and if these similarities exist between the roundworm and social networks it’s reasonable to expect that the structure of other nervous systems is dictated by them as well. </p>
<p class="TXI">But to speak about the structure of the nervous system requires that we know something about the structure of the nervous system. As it turns out, harvesting this information is a nuisance at best and an unprecedented technical hurdle at worst.</p>
<p class="center">* * *</p>
<p class="TXT">A ‘connectome’ is a graph describing the connections in a brain. While Watts and Strogatz were working with an incomplete version, the full roundworm connectome is defined by the full set of 302 neurons in the worm and the 7,286 connections between them. The roundworm was the first animal to have its entire adult connectome documented and, at present, it is the only one. </p>
<p class="TXI">This lack of connectomic data is due largely to the gruelling process by which it is collected. Mapping a full connectome at the neuron level requires fixing a brain in a preservative, cutting it into sheets thinner than a strand of hair, photographing each of these sheets with a microscope and feeding those photographs into a computer that recreates them as a 3D stack. Scientists then spend tens of thousands of hours staring at these photographs, tracing individual neurons through image <a id="page_261"></a>after image and noting where they make contact with each other.<sup><a href="#fn-3" id="fnt-3">3</a>
</sup> The process of unearthing the delicate structure of neural connections this way is as painstaking as a palaeontology dig. The price of all this slicing, stitching and tracing makes it unlikely that full connectomes are within reach for any but the smallest of species. The connectome of the fruit fly, an animal with a brain one-millionth the size of a human’s, is currently being assembled by a team of scientists and producing millions of gigabytes of data in the process. And, while any two roundworms are more or less alike, more complex species tend to have more individual differences, making the connectome of only a single fly or mammal a mere draw from a hat of possible connectomes. </p>
<p class="TXI">Luckily more indirect methods are available that allow for a rough draft of connectomes in many individuals and species. One approach involves recording from a neuron while electrically stimulating others around it. If stimulation of one of these nearby neurons reliably causes a spike in the recorded one, there’s likely a connection between them. Another option is tracers: chemicals that act like dyes that colour in a neuron. To see where inputs are coming from or outputs are going to, one just needs to look at where the dye shows up. None of these methods can create a complete connectome, but they do work to give a snapshot of connectivity in a certain area.</p> <a id="page_262"></a>
<p class="TXI">While connectivity had been studied long before it, the word ‘connectome’ wasn’t coined until 2005. In a visionary paper, psychologist Olaf Sporns and colleagues called on their fellow scientists to help build the connectome of the human brain, promising it would ‘significantly increase our understanding of how functional brain states emerge from their underlying structural substrate’. Getting connection data from humans is a staggering challenge, as many of the invasive methods used in animals are, for obvious reasons, not permissible. A quirk of brain biology, however, allows for a clever alternative. </p>
<p class="TXI">When the brain builds connections, protecting the cargo is key. Like water leaking out of a seeping hose, the electrical signal carried by an axon is at risk of fading away. This isn’t much of a problem for short axons connecting nearby cells, but those carrying signals from one region of the brain to another need protection. Long-range axons therefore get wrapped in layers and layers of a waxy blanket. This waxy substance, called myelin, contains a lot of water molecules. Magnetic resonance imaging (the same technology used to take pictures of tumours, aneurysms and head injuries) can detect the movement of these water molecules – information that is used to reconstruct the tracts of axons in the brain. Through this, it’s possible to see which brain regions are connected to each other. After the publication of Sporns’s plea, the Human Connectome Project was launched to map out the brain using this technique. </p>
<p class="TXI">Identifying long-range axons this way doesn’t produce the same kind of connectome that single-cell tracing methods do. It requires that scientists chunk the brain into <a id="page_263"></a>rough and possibly arbitrary regions; it’s therefore a much coarser description of connectivity. In addition, measuring water molecules isn’t a perfect way to pick up the axons between these areas, leading to errors or ambiguities. Even David Van Essen, one of the key scientists of the Human Connectome Project, warned the neuroscience community in 2016 that there are major technical limitations to this approach that shouldn’t be underappreciated. On the other hand, it is one of the only means by which we can peer into a living human brain; the desire to press forward with it makes sense. As Van Essen wrote: ‘Be optimistic, yet critical of glasses half full and half empty.’ </p>
<p class="TXI">Despite these limitations, neuroscientists in the early 2000s were inspired by the work of Watts and Strogatz 
to look at their field through the lens of graph theory and eagerly set their gaze upon any and all available connectome data. What they saw when they analysed it were small worlds in all directions. The reticular formation, for example, is an ancient part of the brain responsible for many aspects of bodily control. When a cell-level map of this region in cats was pieced together and analysed in 2006, it was the first vertebrate neural circuit to be given the graph-theory treatment. And it was found to be a small world. In studies of the connections between brain areas in both rats and monkeys, short path lengths and plenty of clusters were always found as well. Humans were finally brought into the small-world club in 2007 when researchers in Switzerland used MRI scans to parcellate the brain into a thousand different areas – each about the height and width of a hazelnut – and measured the connections between them.</p> <a id="page_264"></a>
<p class="TXI">Universal findings are a rare sight in neuroscience; the principles that operate on one set of neurons aren’t necessarily assumed to show up in another. As a conclusion that repeats itself across species and scales, small worldness is thus remarkable. Like the refrain of a siren song, it also implores more exploration. To see small worlds in so many places raises questions about how they got there and what roles they can play. While the answers to these questions are still being explored, without the language of graph theory they couldn’t have even been asked in the first place.</p>
<p class="center">* * *</p>
<p class="TXT">On 10 February 2010, approximately 23 per cent of all flights originating in the United States were cancelled. This historically large disruption was the result of a snowstorm in the north-east that closed a handful of airports, including Ronald Reagan in Washington DC and JFK in New York. Such a sizable dent in travel wouldn’t ordinarily come from closing a handful of airports – but these were not just any airports, they were hubs in the aviation network. </p>
<p class="TXI">Hubs are nodes in a graph that have a high degree – that is, they’re highly connected. They reside in the tails of the degree distribution: a plot that shows, for each degree value, how many nodes in the network have that degree (see Figure 21). For graphs like the aviation network or the structure of servers that make up the internet, this graph starts high – meaning that there are many nodes that have only a small number of connections – and fades as the number of connections increases, leading to a long, <a id="page_265"></a>low tail that represents the small number of nodes with very high degree, such as JFK airport. The high degree of hubs makes them powerful but also a potential vulnerability. Like removing the keystone from a stone archway, a targeted attack on one of its hubs can cause a network to collapse.</p>
<p class="image-fig" id="fig21.jpg">
<img alt="" src="Images/chapter-01-image-05.jpg"/></p>
<p class="FC">
<span class="bold">
<span class="italic">Figure 21</span>
</span></p>
<p class="TXI">The brain has hubs. In humans, they’re found sprinkled throughout the lobes. The cingulate, for example, which curves around the centre of the brain, serves as a hub; as does the precuneus, which sits atop the back of the cingulate.<sup><a href="#fn-4" id="fnt-4">4</a>
</sup> In studies of sleep, anaesthesia and people in comas, activity in these areas correlates with consciousness. The size of another hub, the superior frontal cortex, appears correlated with impulsivity and attention. Lesions of a fourth hub, located in the parietal cortex on the side <a id="page_266"></a>of the brain, cause patients to lose a sense of direction. In total, the population of hubs appears diverse in both location and function. The connective thread, if there is any between them, is just how complicated each one is. Regions of the brain like the visual cortex, auditory cortex and olfactory bulb – regions with clear and identifiable roles present right there in their names – don’t make it on to the list of hubs. Hub regions are complex; they pull in information from multiple sources and spread it out just as far. Their role as integrators seems a clear result of their placement in the network architecture. </p>
<p class="TXI">Hubs, in addition to integrating information in distinctive ways, may also be responsible for setting the brain’s clock. In the CA3 region (the memory warehouse of the hippocampus mentioned in <a href="chapter4.xhtml#chapter4">Chapter 4</a>), waves of electrical activity sweep through the neural population in the early days of development after birth. These waves ensure that the activity of the neurons and the strength of their connections are established correctly. And hub neurons are the likely coordinators of this important synchronised activity; they tend to start firing before these waves and stimulating them can instigate a wave. Other studies have even posited a role for hub regions in synchronising activity across the whole brain. Because of their high degree, a message from a hub is heard far and wide in the network. Furthermore, hubs in the brain tend to be strongly interconnected with each other, a network feature referred to as a ‘rich club’. Such connections can ensure all the hubs are themselves on the same page as they send out their synchronising signals. </p>
<p class="TXI">Even the way hub neurons develop points to their special place in the brain. The neurons that go on to form <a id="page_267"></a>the rich club in the roundworm, for example, are some of the first to appear as the nervous system grows. In just eight hours after an egg is fertilised, all of these hub neurons will be born; the rest of the nervous system won’t be finished until over a day later. Similarly, in humans, much of the basic hub structure is present in infants. </p>
<p class="TXI">If hubs are so central to brain function, what role might they play in <span class="italic">dys</span>function? Danielle Bassett explored this question as part of her far-ranging career at the intersection of networks and neuroscience.</p>
<p class="TXI">In the early 2000s, when the methods of graph theory were first being unfurled across the field of neuroscience, Bassett was a college student studying physics. At that time, it might have been a surprise to her to hear she’d go on to be called the ‘doyenne of network science’ by a well-known neuroscientist.<sup><a href="#fn-5" id="fnt-5">5</a>
</sup> Though working towards a physics degree was itself already somewhat surprising given her upbringing: Bassett was one of 11 children home-schooled in a religious family where women were expected to play more traditional roles. Her transition to neuroscience came during her PhD, when she worked with Edward Bullmore, a neuropsychiatrist at Cambridge University who was part of an initial wave of neuroscientists eager to apply graph theory to the brain. One of Bassett’s first projects was to see how the structure of the brain is affected by the common and crippling mental disorder schizophrenia. </p>
<p class="TXI">Schizophrenia is a disease characterised by delusions and disordered thought. Comparing the brains of <a id="page_268"></a>people with the disease to those without, Bassett found several differences in their network properties, including in the hubs. Regions in the frontal cortex that form hubs in healthy people, for example, don’t do so in schizophrenics. A disruption to the frontal cortex and its ability to rein in and control other parts of the brain could relate to the hallucinations and paranoia schizophrenia can elicit. And while the brain of a schizophrenic is still a small world, both the average path length and the strength of clustering are higher than in healthy people, making it seemingly more difficult for two disparate areas to communicate and get on the same page. </p>
<p class="TXI">As the first study to approach this disease from the perspective of graph theory, this work helped bring an old idea about ‘disconnection syndromes’ into the quantitative age. As early as the late nineteenth century, neurologists hypothesised that a disruption in anatomical connections could lead to disorders of thought. German physician Carl Wernicke in particular believed that higher cognitive functions did not reside in any single brain region, but rather emerged from interactions between them. As he wrote in 1885: ‘Any higher psychic process … rested on the mutual interaction of … fundamental psychic elements mediated by means of their manifold connections via the association fibres.’ Lesioning these ‘association fibres’, he posited, would impair complex functions like language, awareness and planning. </p>
<p class="TXI">Now that the tools of graph theory have met the study of ‘disconnection syndromes’, more diseases of this kind are being explored with modern approaches. One <a id="page_269"></a>common example is Alzheimer’s disease. When the brain-wide connectivity of older patients with Alzheimer’s was compared to those without it, it was found that those with Alzheimer’s had longer path lengths between brain areas. The confusion and cognitive impairment of Alzheimer’s disease may result, in part, from the breakdown of efficient communication between distant brain regions. Similar changes in brain network structures are seen to a lesser extent with normal ageing. </p>
<p class="TXI">Since starting her own lab at the University of Pennsylvania in 2013, Bassett has moved on from just observing the structure of the brain in health and disease to figuring out how to exploit it. The activity of complex networks can be hard to predict. A rumour whispered to a friend could die out immediately or spread across your social network, depending on the structure of that network and your friend’s place within it. The effects of stimulating or silencing neurons can be equally hard to anticipate. The Bassett lab is combining tools from engineering with knowledge about the structure of brain networks to make control of neural activity more tractable. In particular, models based on the brain-wide connectomes of individual people were used to determine exactly where brain stimulation should be applied in order to have the desired effect. The aim is to use this individualised treatment to get disorders like Parkinson’s disease and epilepsy under control. </p>
<p class="TXI">The hope that the metrics of graph theory may serve as markers of disease – potentially even early markers that could lead to preventative care – has made them quite popular in medical research. Thus far, the brain <a id="page_270"></a>disorders scrutinised by network analysis include Alzheimer’s, schizophrenia, traumatic brain injury, multiple sclerosis, epilepsy, autism and bipolar disorder. Results, however, have been mixed. As was pointed out, the MRI technique for collecting the data in the first place has its problems and some studies find disease signatures that others don’t. Overall, with so many excited scientists on the hunt for differences between diseased and healthy brains, some false positives and faulty data are bound to get caught up in the findings. But whether the results are solidified yet or not, it’s safe to say this new slate of tools has made an arrival on the clinical scene. </p>
<p class="center">* * *</p>
<p class="TXT">A developing brain is an eruption. Neurons bubble out of a neuronal nursery called the ventricular zone at a breakneck pace and pour into all corners of the burgeoning brain. Once there, they start making connections. These indiscriminate neurons form synapse after synapse with each other, frenetically linking cells near and far. At the height of synapse building in the human brain – during the third trimester of pregnancy – 40,000 such connections are constructed every second. Development is an explosion of neuronal and synaptic genesis. </p>
<p class="TXI">But just as soon as they come, many of these cells and connections go. An adult has far fewer neurons than they had in the womb; as many as half the neurons produced during development die. The number of <a id="page_271"></a>connections a neuron in the cortex makes peaks around the first year of life and gets reduced by a third thereafter. The brain is thus built via a surge and a retreat, a swelling and a shrinking. During development, the pruning of neurons and synapses is ruthless; only the useful survive. Synapses, for example, are built to carry signals between neurons. If no signal flows, the synapse must go. Out of this turmoil and turnover emerge operational neural circuits. It’s like encouraging the overgrowth of shrubbery for the purpose of carving delicate topiary out of it.</p>
<p class="TXI">Such is the way biology found to build the brain. But if you asked a graph theorist how to make a network, they’d give the exact opposite answer. The designer of a public transit system, for example, wouldn’t start by building a bunch of train stations and bus stops and connecting them all up just to see what gets used. No government would approve such a waste of resources. Rather, most graphs are built from the bottom up. For example, one strategy graph theorists use is to first build a graph that – using the fewest edges possible – has a path between any two nodes. This means some paths may be quite long, but by observing what paths get used the most (by commuters on a train or information travelling between servers on the internet) the network designer can identify where it would be useful to add a shortcut. Thus, the network gets more efficient by adding well-placed edges. </p>
<p class="TXI">The brain, however, doesn’t have a designer. There is no central planner that can look down and say: ‘It looks like signals would flow better if that neuron over there <a id="page_272"></a>was connected to this one here.’<sup><a href="#fn-6" id="fnt-6">6</a>
</sup> That is why the brain needs to overproduce and prune. The only way the brain can make decisions about which connections should exist is by calculating the activity that passes through those connections. Individual neurons and synapses have elaborate molecular machinery for measuring how much use they’re getting and growing or shrivelling as a result. If the connection doesn’t exist in the first place, though, the activity on it can’t be measured.</p>
<p class="TXI">Pruning of connections in the brain starts off very strong, with synapses getting slashed left and right, but it then slows down over time. In 2015, scientists at the Salk Institute and Carnegie Mellon University explored why this pattern of pruning may be beneficial to the brain. To do so, they simulated networks that started overgrown and were pruned via a ‘use it or lose it’ principle. Importantly, they varied just how quickly this pruning happened. They found that networks that mimicked the pruning process in the brain (with the rate of pruning high initially and lowering over time) ended up with short average path lengths and were capable of effectively routing information even if some nodes or edges were deleted. This efficiency and robustness wasn’t as strong in networks where the pruning rate was constant, or increased, over time. A decreasing pruning rate, it seems, has the benefit of quickly eliminating useless connections while still <a id="page_273"></a>allowing the network enough time to fine-tune the structure that remains; a sculptor working with marble, similarly, may be quick to cut out the basic shape of a man, but carving the fine details of the body is a slow and careful process. While most physical networks like roads or telephone lines will never be built based on pruning, digital networks that don’t have costs associated with constructing edges – such as those formed by the wireless communication between mobile devices – could benefit from brain-inspired algorithms. </p>
<p class="center">* * *</p>
<p class="TXT">Network neuroscience, the name given to this practice of using the equipment of graph theory and network science to interrogate the structures of the brain, is a young field. <span class="italic">Network Neuroscience</span>, the first academic journal dedicated solely to this endeavour, was first published in 2017. New tools for mapping out connectomes at multiple scales have coincided with the computational power to analyse larger and larger datasets. The result is an electrified environment, with ever more and diverse studies of structure conducted every day. </p>
<p class="TXI">A reason for caution, however, may be found in the stomach of a lobster.</p>
<p class="TXI">The stomatogastric ganglion is a circuit of 25–30 neurons located in the gut of lobsters and other crustaceans. These neurons conspire through their connections to perform a basic but crucial job: produce the rhythmic muscle contractions that guide digestion. Eve Marder, a professor at Brandeis University in <a id="page_274"></a>Massachusetts, has spent half a century studying this handful of neurons. </p>
<p class="TXI">Marder was born and raised in New York but her education took her to Massachusetts and then California.<sup><a href="#fn-7" id="fnt-7">7</a>
</sup> While her doctorate work at the University of California, San Diego, was solidly in neuroscience, Marder always had an aptitude for mathematics: in primary school, she worked her way through maths textbooks meant for students two years her senior. This polymath personality permeates her science. Throughout her career she has collaborated with researchers from many backgrounds, including Larry Abbott (mentioned in <a href="chapter1.xhtml#chapter1">Chapter 1</a>), as he was making his transition from a particle physicist to renowned theoretical neuroscientist. Blending experimental exactness with a mathematical mindset, Marder has thoroughly probed the functioning of this little lobster circuit both physically and in computer simulations.</p>
<p class="TXI">The connectome of the lobster stomatogastric ganglion has been known since the 1980s. The 30 neurons of this ganglion form 195 connections and send outputs to the muscles of the stomach. For her PhD, Marder worked out what chemicals these neurons use to communicate. In addition to standard neurotransmitters – the chemicals that traverse the small synaptic cleft between the neuron releasing them and the one receiving <a id="page_275"></a>them – Marder also found a panoply of neuromodulators at play. </p>
<p class="TXI">Neuromodulators are chemicals that fiddle with the settings of a neural circuit. They can turn the strength of connections between neurons up or down and make neurons fire more, less or in different patterns. Neuromodulators effect these changes by latching on to receptors embedded in a neuron’s cell membrane. Part of what’s noteworthy about neuromodulators is where they come from and how they get to the neuron. In the most extreme case, a neuromodulator could be released from a different part of the brain or body and travel through the blood to its destination. Other times, a neuromodulator is released locally from nearby neurons – but whether from near or afar, neuromodulators tend to bathe a circuit indiscriminately, touching many neurons and synapses in a diffuse way. Whereas regular neurotransmission is like a letter sent between two neurons, neuromodulation is a leaflet sent out to the whole community.</p>
<p class="TXI">In the 1990s, Marder, along with members of her lab and the lab of Michael Nusbaum, a professor at the University of Pennsylvania, experimented with neuromodulators in the stomatogastric ganglion circuit. Ordinarily, the circuit produces a steady rhythm, with certain neurons in the population firing about once per second. But, when the experimenters released neuromodulators on to the circuit, this behaviour changed. Some neuromodulators made the rhythm increase: the same neurons fired, but more frequently. Others made the rhythm decrease, and some had a more dramatic effect, both disrupting the rhythm and <a id="page_276"></a>activating neurons that were ordinarily silent. The neuromodulators causing these changes were all released from neurons that normally provide input to this circuit. This means these different patterns of output are plausibly produced naturally throughout the animal’s life. In more artificial settings, neuromodulators added by the experimenters can cause even larger and more diverse changes. </p>
<p class="TXI">Importantly, throughout these experiments the underlying network never changed. No neurons were added or deleted, nor did they cut or grow any connections. The marked changes in behaviour stemmed solely from a small sprinkling of neuromodulators atop a steady structure. </p>
<p class="TXI">The massive effort poured into getting a connectome presupposes a certain amount of payoff that will come from having it, but the payoff is less if the structure-function relationship is looser than it may have seemed. If neuromodulators can release the activity of neurons in a circuit from the strict constraints of their architecture, then structure is not destiny. Perhaps this wouldn’t be such a concern if neuromodulation were a phenomenon specific to the stomatogastric ganglion. This, however, is far from the truth. Brains are constantly bathing in modulating molecules. Across species, neuromodulators are responsible for everything from sleeping to learning, moulting to eating. Neuromodulation is the rule, not the exception. </p>
<p class="TXI">Through mathematical simulations of the circuits she studies, Marder has explored not just how different behaviours arise from the same structure, but also how <a id="page_277"></a>
<span class="italic">different</span> structures can produce the <span class="italic">same</span> behaviours. Specifically, each lobster has a slightly different configuration of its gut circuitry: connections may be built stronger or weaker in one animal versus another. By simulating as many as 20 million possible ganglion circuits, Marder’s lab found that the vast majority aren’t capable of producing the needed rhythms, but certain specific configurations are. Each lobster, through some combination of genes and development, finds its way to one of these functioning configurations. The work makes an important point about individual brains: diversity doesn’t always mean difference. What may look like a deviation from the structural norm could in fact be a perfectly valid way to achieve the same outcomes. That these diverse structures create the same rhythms adds another wrinkle to the structure-function relationship.</p>
<p class="TXI">As much as Marder’s work shows the limits of structure for understanding function, it also shows the need for it. Her lifetime of work – and all the insights it has provided – is built atop the connectome. Without that detailed structural information, there is no structure-function relationship to be explored. As Marder wrote in 2012: ‘Detailed anatomical data are invaluable. No circuit can be fully understood without a connectivity diagram.’ However, she goes on to remark that ‘a connectivity diagram is only a necessary beginning, but not in itself, an answer’. In other words, when it comes to understanding the brain, knowing the structure of the nervous system is both completely necessary and utterly insufficient.</p><a id="page_278"></a>
<p class="TXI">So, it may not be possible to satisfy Cajal’s vision of intuiting the function of the nervous system from mere meditations on its structure. But the work of finding and formalising that structure is still an important prerequisite for any further understanding of the brain. Innovative methods for gathering connectome data are blossoming and the formalisms of graph theory are in place, prepared to take in and digest that data.</p>
<p class="H1">Notes</p>
<p class="FN1"><a href="chapter9.xhtml#fnt-1" id="fn-1">1</a> ﻿The images were attractive enough to be the centrepiece of a travelling art exhibition called ﻿<span class="italic">The Beautiful Brain</span>﻿, a fate that surely would﻿’﻿ve pleased Cajal. Before succumbing to his father﻿’﻿s wishes that he be a physician, Cajal dreamt of being an artist.﻿</p>
<p class="FN1"><a href="chapter9.xhtml#fnt-2" id="fn-2">2</a> ﻿Milgram﻿’﻿s experiment has been criticised by later researchers for lacking rigour. He didn﻿’﻿t, for example, take into account the folders that never made it to the target person. As a result, whether six really is the magic number when it comes to degrees of separation between people has remained an open question. Luckily, data from social media sites is offering new ways to answer it. ﻿</p>
<p class="FN1"><a href="chapter9.xhtml#fnt-3" id="fn-3">3</a> ﻿There are currently some successful attempts to automate this arduous process. In the meantime, desperate scientists have also tried to turn this work into a game and get people all over the world to play it. It can be found at ﻿﻿eyewire.org﻿﻿.﻿</p>
<p class="FN1"><a href="chapter9.xhtml#fnt-4" id="fn-4">4</a> ﻿A note of caution: precisely what features a brain area needs to have to be considered a hub is debated. And even applying the same definition to different datasets can lead to different conclusions. As it is still early days for this style of analysis, such kinks will take time to work out.﻿</p>
<p class="FN1"><a href="chapter9.xhtml#fnt-5" id="fn-5">5</a> ﻿British neuroscientist Karl Friston bestowed this title on Bassett in a 2019 interview in ﻿<span class="italic">Science</span>﻿. We﻿’﻿ll hear more about Friston in ﻿﻿Chapter 12﻿﻿.﻿</p>
<p class="FN1"><a href="chapter9.xhtml#fnt-6" id="fn-6">6</a> ﻿There may be an exception to this in very simple animals, such as ﻿<span class="italic">C. elegans</span>﻿, where it﻿’﻿s believed a lot of the information about who should connect to whom is encoded in the genome and is thus ﻿‘﻿designed﻿’﻿ through eons of natural selection.﻿</p>
<p class="FN1"><a href="chapter9.xhtml#fnt-7" id="fn-7">7</a> ﻿Marder entered graduate school in 1969, a time at which women were becoming a more common sight in these programmes, but barriers still existed. As she recounts in her autobiography, ﻿‘﻿I knew it unlikely that I would get into Stanford biology because they were widely said to have a quota on women (2 out of 12).﻿’﻿﻿</p>
</body>
</html>
<html lang="en" xml:lang="en" xmlns="http://www.w3.org/1999/xhtml" xmlns:epub="http://www.idpf.org/2007/ops" xmlns:mml="http://www.w3.org/1998/Math/MathML">
<head>
<meta charset="utf-8"/>
<title>Contents</title>
<link href="../styles/stylesheet.css" rel="stylesheet" type="text/css"/>
<meta content="urn:uuid:e0000000-0000-0000-0000-000006607108" name="Adept.expected.resource"/>
</head>
<body>
<p class="FMT" id="re_contents">Contents</p>
<p class="TOC-CH"><a href="chapter1.xhtml#chapter1" id="re_chapter1">Chapter 1:  Spherical Cows</a></p>
<p class="TOC-CH"><a href="chapter2.xhtml#chapter2" id="re_chapter2">Chapter 2:  How Neurons Get Their Spike</a></p>
<p class="TOC-CH"><a href="chapter3.xhtml#chapter3" id="re_chapter3">Chapter 3:  Learning to Compute</a></p>
<p class="TOC-CH"><a href="chapter4.xhtml#chapter4" id="re_chapter4">Chapter 4:  Making and Maintaining Memories</a></p>
<p class="TOC-CH"><a href="chapter5.xhtml#chapter5" id="re_chapter5">Chapter 5:  Excitation and Inhibition</a></p>
<p class="TOC-CH"><a href="chapter6.xhtml#chapter6" id="re_chapter6">Chapter 6:  Stages of Sight</a></p>
<p class="TOC-CH"><a href="chapter7.xhtml#chapter7" id="re_chapter7">Chapter 7:  Cracking the Neural Code</a></p>
<p class="TOC-CH"><a href="chapter8.xhtml#chapter8" id="re_chapter8">Chapter 8:  Movement in Low Dimensions</a></p>
<p class="TOC-CH"><a href="chapter9.xhtml#chapter9" id="re_chapter9">Chapter 9:  From Structure to Function</a></p>
<p class="TOC-CH"><a href="chapter10.xhtml#chapter10" id="re_chapter10">Chapter 10:  Making Rational Decisions</a></p>
<p class="TOC-CH"><a href="chapter11.xhtml#chapter11" id="re_chapter11">Chapter 11:  How Rewards Guide Actions</a></p>
<p class="TOC-CH"><a href="chapter12.xhtml#chapter12" id="re_chapter12">Chapter 12:  Grand Unified Theories of the Brain</a></p>
<p class="TOC-CH1"><a href="Mathematical.xhtml#Mathematical" id="re_Mathematical">Mathematical Appendix</a></p>
<p class="TOC-CH"><a href="ack.xhtml#ack" id="re_ack">Acknowledgements</a></p>
<p class="TOC-CH"><a href="bib.xhtml#bib" id="re_bib">Bibliography</a></p>
<p class="TOC-CH"><a href="index.xhtml#index" id="re_index">Index</a></p>
</body>
</html>